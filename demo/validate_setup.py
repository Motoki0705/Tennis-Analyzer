#!/usr/bin/env python
"""
VideoPredictor Demo Setup Validator
===================================

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€VideoPredictor Demo ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«
å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚„è¨­å®šãŒæ­£ã—ãç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python demo/validate_setup.py
    python demo/validate_setup.py --config_path demo/my_config.yaml
"""

import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import torch
from omegaconf import OmegaConf, DictConfig

# ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append('.')


def check_file_exists(file_path: str, description: str) -> bool:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèª"""
    path = Path(file_path)
    if path.exists():
        print(f"âœ… {description}: {file_path}")
        return True
    else:
        print(f"âŒ {description}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return False


def check_directory_exists(dir_path: str, description: str) -> bool:
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ã‚’ç¢ºèª"""
    path = Path(dir_path)
    if path.exists() and path.is_dir():
        print(f"âœ… {description}: {dir_path}")
        return True
    else:
        print(f"âŒ {description}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dir_path}")
        return False


def check_python_packages() -> bool:
    """å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®å­˜åœ¨ã‚’ç¢ºèª"""
    required_packages = [
        "torch",
        "torchvision", 
        "transformers",
        "hydra-core",
        "omegaconf",
        "cv2",
        "tqdm",
        "numpy",
        "PIL"
    ]
    
    print("\nğŸ“¦ å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª:")
    missing_packages = []
    
    for package in required_packages:
        try:
            if package == "cv2":
                import cv2
                print(f"âœ… opencv-python: {cv2.__version__}")
            elif package == "PIL":
                import PIL
                print(f"âœ… Pillow: {PIL.__version__}")
            else:
                module = __import__(package.replace("-", "_"))
                if hasattr(module, '__version__'):
                    print(f"âœ… {package}: {module.__version__}")
                else:
                    print(f"âœ… {package}: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
        except ImportError:
            print(f"âŒ {package}: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâŒ ä»¥ä¸‹ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        for package in missing_packages:
            print(f"   pip install {package}")
        return False
    
    return True


def check_config_file(config_path: str) -> Tuple[bool, DictConfig]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
    print(f"\nğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼: {config_path}")
    
    try:
        cfg = OmegaConf.load(config_path)
        print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿æˆåŠŸ")
        
        # å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèª
        required_sections = ["common", "ball", "court", "player", "pose", "processors", "predictors"]
        missing_sections = []
        
        for section in required_sections:
            if section in cfg:
                print(f"âœ… {section}ã‚»ã‚¯ã‚·ãƒ§ãƒ³: å­˜åœ¨")
            else:
                print(f"âŒ {section}ã‚»ã‚¯ã‚·ãƒ§ãƒ³: ä¸è¶³")
                missing_sections.append(section)
        
        if missing_sections:
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_sections}")
            return False, cfg
        
        return True, cfg
        
    except Exception as e:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False, None


def check_model_checkpoints(cfg: DictConfig) -> bool:
    """ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª"""
    print(f"\nğŸ’¾ ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª:")
    
    all_exist = True
    
    # Lightning moduleã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¢ºèª
    lightning_tasks = ["ball", "court", "player"]
    for task in lightning_tasks:
        if task in cfg:
            ckpt_path = cfg[task].get("ckpt_path")
            if ckpt_path:
                exists = check_file_exists(ckpt_path, f"{task}ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ")
                all_exist = all_exist and exists
            else:
                print(f"âŒ {task}ãƒ¢ãƒ‡ãƒ«ã®ckpt_pathãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                all_exist = False
    
    # Transformersãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
    if "pose" in cfg:
        pose_model = cfg.pose.get("pretrained_model_name_or_path")
        if pose_model:
            print(f"âœ… poseãƒ¢ãƒ‡ãƒ«(Transformers): {pose_model}")
        else:
            print(f"âŒ poseãƒ¢ãƒ‡ãƒ«ã®pretrained_model_name_or_pathãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            all_exist = False
    
    return all_exist


def check_predictors_config(cfg: DictConfig) -> bool:
    """äºˆæ¸¬å™¨è¨­å®šã®ç¢ºèª"""
    print(f"\nğŸ”§ äºˆæ¸¬å™¨è¨­å®šã®ç¢ºèª:")
    
    all_valid = True
    
    # å¿…è¦ãªäºˆæ¸¬å™¨ã®ç¢ºèª
    required_predictors = ["ball", "court", "pose", "streaming_overlayer"]
    for predictor in required_predictors:
        if predictor in cfg.predictors:
            print(f"âœ… {predictor}äºˆæ¸¬å™¨: è¨­å®šæ¸ˆã¿")
        else:
            print(f"âŒ {predictor}äºˆæ¸¬å™¨: è¨­å®šä¸è¶³")
            all_valid = False
    
    # streaming_overlayerã®è©³ç´°ç¢ºèª
    if "streaming_overlayer" in cfg.predictors:
        overlayer_cfg = cfg.predictors.streaming_overlayer
        
        # å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª
        required_params = ["intervals", "batch_sizes"]
        for param in required_params:
            if param in overlayer_cfg:
                print(f"âœ… streaming_overlayer.{param}: {overlayer_cfg[param]}")
            else:
                print(f"âŒ streaming_overlayer.{param}: è¨­å®šä¸è¶³")
                all_valid = False
    
    return all_valid


def check_device_availability(cfg: DictConfig) -> bool:
    """ãƒ‡ãƒã‚¤ã‚¹åˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª"""
    print(f"\nğŸ–¥ï¸ ãƒ‡ãƒã‚¤ã‚¹åˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª:")
    
    device = cfg.common.get("device", "cpu")
    
    if device == "cuda":
        if torch.cuda.is_available():
            print(f"âœ… CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.get_device_name(0)}")
            print(f"   GPU ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            return True
        else:
            print(f"âŒ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return False
    else:
        print(f"âœ… CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="VideoPredictor Demo ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¤œè¨¼ãƒ„ãƒ¼ãƒ«"
    )
    parser.add_argument(
        "--config_path",
        type=str,
        default="configs/infer/infer.yaml",
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    
    args = parser.parse_args()
    
    print("ğŸ” VideoPredictor Demo ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™...")
    print("=" * 60)
    
    # æ¤œè¨¼çµæœã‚’è¨˜éŒ²
    results = []
    
    # 1. Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
    results.append(check_python_packages())
    
    # 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    config_valid, cfg = check_config_file(args.config_path)
    results.append(config_valid)
    
    if not config_valid:
        print("\nâŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã«å¤±æ•—ã—ãŸãŸã‚ã€ä»¥é™ã®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        sys.exit(1)
    
    # 3. ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª
    results.append(check_model_checkpoints(cfg))
    
    # 4. äºˆæ¸¬å™¨è¨­å®šã®ç¢ºèª
    results.append(check_predictors_config(cfg))
    
    # 5. ãƒ‡ãƒã‚¤ã‚¹åˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª
    results.append(check_device_availability(cfg))
    
    # 6. é‡è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    print(f"\nğŸ“ é‡è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª:")
    dir_results = []
    dir_results.append(check_directory_exists("src/multi/streaming_overlayer", "StreamingOverlayerãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"))
    dir_results.append(check_directory_exists("src/predictors", "Predictorsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"))
    
    results.extend(dir_results)
    
    # çµæœã®é›†è¨ˆ
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¤œè¨¼çµæœã®é›†è¨ˆ:")
    
    passed = sum(results)
    total = len(results)
    
    if passed == total:
        print(f"âœ… ã™ã¹ã¦ã®æ¤œè¨¼ã«åˆæ ¼ã—ã¾ã—ãŸï¼ ({passed}/{total})")
        print("ğŸš€ VideoPredictor Demo ã®å®Ÿè¡Œæº–å‚™ãŒæ•´ã„ã¾ã—ãŸ")
        
        print("\nğŸ”¥ å®Ÿè¡Œä¾‹:")
        print("python demo/video_predictor_demo.py \\")
        print("    --input_path datasets/test/input.mp4 \\")
        print("    --output_path outputs/demo_output.mp4")
        
        sys.exit(0)
    else:
        print(f"âŒ æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ ({passed}/{total})")
        print("ğŸ”§ ä¸Šè¨˜ã®å•é¡Œã‚’è§£æ±ºã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
        sys.exit(1)


if __name__ == "__main__":
    main() 