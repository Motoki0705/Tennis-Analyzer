#!/usr/bin/env python
"""
VideoPredictor Demo - å‹•ç”»äºˆæ¸¬å™¨ãƒ‡ãƒ¢å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
==================================================

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€src/multi/streaming_overlayer/video_predictor.py ã‚’ä½¿ç”¨ã—ã¦
ãƒ†ãƒ‹ã‚¹å‹•ç”»ã«å¯¾ã—ã¦ãƒœãƒ¼ãƒ«ãƒ»ã‚³ãƒ¼ãƒˆãƒ»ãƒãƒ¼ã‚ºã®ä¸¦åˆ—æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ãƒ¢ã§ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python demo/video_predictor_demo.py --input_path datasets/test/input.mp4 --output_path outputs/demo_output.mp4

ã¾ãŸã¯ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œ:
    python demo/video_predictor_demo.py --config_path configs/infer/infer.yaml --input_path datasets/test/input.mp4
"""

import argparse
import logging
import sys
from pathlib import Path
from typing import Dict, Any

import torch
import hydra
from hydra.utils import instantiate, to_absolute_path
from omegaconf import DictConfig, OmegaConf

# ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append('.')

from src.multi.streaming_overlayer.video_predictor import VideoPredictor

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)


def instantiate_model(cfg: DictConfig, task: str) -> torch.nn.Module:
    """
    ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚
    
    Args:
        cfg (DictConfig): å…¨ä½“è¨­å®š
        task (str): ã‚¿ã‚¹ã‚¯å ('ball', 'court', 'player', 'pose', 'event')
        
    Returns:
        torch.nn.Module: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
    """
    task_cfg = cfg[task]
    target_class = task_cfg.get("_target_", "")
    
    if not target_class:
        raise ValueError(f"_target_ is required for task '{task}'")
    
    logger.info(f"ğŸ“¥ {task} ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {target_class}")
    
    # transformersãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼ˆposeã‚¿ã‚¹ã‚¯ãªã©ï¼‰
    if target_class.startswith("transformers."):
        logger.info(f"ğŸ¤— transformers.from_pretrained ã‚’ä½¿ç”¨: {task}")
        model = instantiate(task_cfg)
        return model
    
    # LightningModuleã®å ´åˆï¼ˆball, court, player, eventã‚¿ã‚¹ã‚¯ãªã©ï¼‰
    ckpt_path = task_cfg.get("ckpt_path")
    if not ckpt_path:
        raise ValueError(f"ckpt_path is required for LightningModule task '{task}'")
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã¨ã‚¯ãƒ©ã‚¹åã‚’åˆ†é›¢
    try:
        module_path, class_name = target_class.rsplit('.', 1)
    except ValueError:
        raise ValueError(f"Invalid _target_ format for task '{task}': {target_class}")
    
    try:
        # å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        import importlib
        module = importlib.import_module(module_path)
        model_cls = getattr(module, class_name)
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
        ckpt_abs = to_absolute_path(ckpt_path)
        logger.info(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ­ãƒ¼ãƒ‰: {ckpt_abs}")
        
        if not Path(ckpt_abs).exists():
            raise FileNotFoundError(f"Checkpoint not found: {ckpt_abs}")
            
        model = model_cls.load_from_checkpoint(ckpt_abs)
        return model
        
    except Exception as e:
        logger.error(f"âŒ {task} ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        raise


def create_ball_predictor(cfg: DictConfig, device: str, use_half: bool):
    """ãƒœãƒ¼ãƒ«äºˆæ¸¬å™¨ã‚’ä½œæˆ"""
    logger.info("ğŸ¾ ãƒœãƒ¼ãƒ«äºˆæ¸¬å™¨ã‚’åˆæœŸåŒ–ä¸­...")
    ball_model = instantiate_model(cfg, "ball").to(device)
    
    return instantiate(
        cfg.predictors.ball,
        litmodule=ball_model,
        device=device,
        use_half=use_half
    )


def create_court_predictor(cfg: DictConfig, device: str, use_half: bool):
    """ã‚³ãƒ¼ãƒˆäºˆæ¸¬å™¨ã‚’ä½œæˆ"""
    logger.info("ğŸŸï¸ ã‚³ãƒ¼ãƒˆäºˆæ¸¬å™¨ã‚’åˆæœŸåŒ–ä¸­...")
    court_model = instantiate_model(cfg, "court").to(device)
    
    return instantiate(
        cfg.predictors.court,
        litmodule=court_model,
        device=device,
        use_half=use_half
    )


def create_pose_predictor(cfg: DictConfig, device: str, use_half: bool):
    """ãƒãƒ¼ã‚ºäºˆæ¸¬å™¨ã‚’ä½œæˆ"""
    logger.info("ğŸ¤¸ ãƒãƒ¼ã‚ºäºˆæ¸¬å™¨ã‚’åˆæœŸåŒ–ä¸­...")
    
    # æ¤œå‡ºå™¨ï¼ˆplayerï¼‰ã¯LightningModuleã‚’ä½¿ç”¨
    player_model = instantiate_model(cfg, "player").to(device)
    det_processor = instantiate(cfg.processors.player)
    
    # ãƒãƒ¼ã‚ºæ¨å®šï¼ˆposeï¼‰ã¯Transformersã‚’ä½¿ç”¨
    pose_model = instantiate_model(cfg, "pose").to(device)
    pose_processor = instantiate(cfg.processors.pose)
    
    return instantiate(
        cfg.predictors.pose,
        det_litmodule=player_model,
        det_processor=det_processor,
        pose_litmodule=pose_model,
        pose_processor=pose_processor,
        device=device,
        use_half=use_half
    )


def load_config(config_path: str = None) -> DictConfig:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    if config_path is None:
        config_path = Path(__file__).parent.parent / "configs" / "infer" / "infer.yaml"
    
    logger.info(f"ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {config_path}")
    
    if not Path(config_path).exists():
        raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
    
    cfg = OmegaConf.load(config_path)
    
    # å¿…è¦ãªè¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§è£œå®Œ
    if "common" not in cfg:
        cfg.common = {}
    cfg.common.setdefault("device", "cuda" if torch.cuda.is_available() else "cpu")
    cfg.common.setdefault("use_half", True)
    cfg.common.setdefault("batch_size", 16)
    
    return cfg


def setup_video_predictor(cfg: DictConfig, input_path: str, output_path: str) -> VideoPredictor:
    """VideoPredictor ã‚’è¨­å®šãƒ»åˆæœŸåŒ–"""
    device = cfg.common.device
    use_half = cfg.common.use_half
    
    logger.info(f"ğŸ–¥ï¸ ãƒ‡ãƒã‚¤ã‚¹: {device}")
    logger.info(f"ğŸ“Š Half precision: {use_half}")
    
    # å„äºˆæ¸¬å™¨ã®åˆæœŸåŒ–
    ball_predictor = create_ball_predictor(cfg, device, use_half)
    court_predictor = create_court_predictor(cfg, device, use_half)
    pose_predictor = create_pose_predictor(cfg, device, use_half)
    
    # å‡¦ç†é–“éš”ã¨ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨­å®š
    streaming_overlayer_cfg = cfg.predictors.streaming_overlayer
    intervals = streaming_overlayer_cfg.get("intervals", {"ball": 1, "court": 30, "pose": 5})
    batch_sizes = streaming_overlayer_cfg.get("batch_sizes", {"ball": 16, "court": 16, "pose": 16})
    debug = streaming_overlayer_cfg.get("debug", False)
    
    logger.info(f"â±ï¸ å‡¦ç†é–“éš”: {intervals}")
    logger.info(f"ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_sizes}")
    
    # VideoPredictor ã®åˆæœŸåŒ–
    video_predictor = VideoPredictor(
        ball_predictor=ball_predictor,
        court_predictor=court_predictor,
        pose_predictor=pose_predictor,
        intervals=intervals,
        batch_sizes=batch_sizes,
        debug=debug,
        custom_queue_configs=streaming_overlayer_cfg.get("custom_queue_configs"),
        hydra_queue_config=cfg.get("queue") if "queue" in cfg else None,
        max_preload_frames=64,
        enable_performance_monitoring=True
    )
    
    return video_predictor


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="VideoPredictor Demo - ãƒ†ãƒ‹ã‚¹å‹•ç”»ã®ä¸¦åˆ—æ¨è«–ãƒ‡ãƒ¢",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "--input_path", 
        type=str, 
        required=True,
        help="å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--output_path", 
        type=str, 
        required=True,
        help="å‡ºåŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--config_path", 
        type=str, 
        default=None,
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ï¼‰"
    )
    parser.add_argument(
        "--device", 
        type=str, 
        default=None,
        help="ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ï¼ˆcuda/cpuï¼‰"
    )
    parser.add_argument(
        "--debug", 
        action="store_true",
        help="ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ"
    )
    
    args = parser.parse_args()
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not Path(args.input_path).exists():
        logger.error(f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_path}")
        sys.exit(1)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_path = Path(args.output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        logger.info("ğŸš€ VideoPredictor ãƒ‡ãƒ¢ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        cfg = load_config(args.config_path)
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã®ä¸Šæ›¸ã
        if args.device:
            cfg.common.device = args.device
        
        # ãƒ‡ãƒãƒƒã‚°è¨­å®šã®ä¸Šæ›¸ã
        if args.debug:
            cfg.predictors.streaming_overlayer.debug = True
        
        # VideoPredictor ã®è¨­å®šãƒ»åˆæœŸåŒ–
        video_predictor = setup_video_predictor(cfg, args.input_path, args.output_path)
        
        # å‹•ç”»å‡¦ç†ã®å®Ÿè¡Œ
        logger.info(f"ğŸ“¹ å‹•ç”»å‡¦ç†ã‚’é–‹å§‹: {args.input_path} â†’ {args.output_path}")
        video_predictor.run(args.input_path, args.output_path)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã®è¡¨ç¤º
        metrics = video_predictor.get_performance_metrics()
        logger.info("ğŸ“Š å‡¦ç†å®Œäº†ï¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ:")
        logger.info(f"  â€¢ ç·å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {metrics.get('total_frames_processed', 'N/A')}")
        logger.info(f"  â€¢ ç·å‡¦ç†æ™‚é–“: {metrics.get('total_processing_time', 'N/A'):.2f} ç§’")
        logger.info(f"  â€¢ å¹³å‡FPS: {metrics.get('frames_per_second', 'N/A'):.2f}")
        
        logger.info(f"âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.output_path}")
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
        
    except Exception as e:
        logger.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 