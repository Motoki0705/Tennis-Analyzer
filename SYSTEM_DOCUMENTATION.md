# テニス動画解析システム 総合ドキュメント

## 1. プロジェクト概要 (Executive Summary)

### 1.1. 目的
本プロジェクトは、テニス動画から多様な情報を自動的に抽出し、分析するためのAIプラットフォームです。主な目的は、試合の戦術分析、選手のパフォーマンス評価、および動画のハイライト生成を支援することです。

### 1.2. 主要機能
システムは以下の5つのコア機能から構成されています。
- **ボール検出・追跡**: 高精度なボール検出と軌跡追跡
- **コート検出**: テニスコートの主要な線とキーポイントの認識
- **選手検出**: リアルタイムでの選手の位置特定
- **姿勢推定**: 選手の骨格キーポイントを推定し、フォームを解析
- **イベント検出**: 上記情報を統合し、「ヒット」や「バウンド」などの重要イベントを時系列で特定

### 1.3. 技術的成果
- 軽量モデル(LiteTrackNet)と高精度モデル(Video Swin Transformer)の選択肢を提供。
- リアルタイム物体検出モデル(RT-DETR)をテニス選手検出に特化させてファインチューニング。
- 複数の異なる情報源（ボール、コート、選手、姿勢）を統合し、文脈を理解するマルチモーダルTransformer（EventTransformerV2）を実装。
- PyTorch Lightningによる再現性の高い学習パイプラインと、Hydraによる柔軟な設定管理を実現。

### 1.4. 使用場面
- **プロ・アマチュアの試合分析**: 選手のポジショニング、ボールの軌道、ショットの種類などをデータ化し、戦術研究に活用。
- **コーチング支援**: 選手のフォームを骨格レベルで解析し、改善点を可視化。
- **メディア・放送**: 試合のハイライトシーン（ラリー、エースなど）を自動生成。
- **個人プレイヤー**: 自身のプレイを客観的に分析し、スキル向上に役立てる。

---

## 2. システムアーキテクチャ

### 2.1. 全体構成図 (詳細版)
本システムは、動画を入力とし、分析結果を可視化した動画とイベント確率グラフを出力するエンドツーエンドのパイプラインです。

```mermaid
graph TD
    A[動画ファイル (.mp4)] --> B{1. フレーム抽出 & バッチ化};
    B --> C{2a. ボール特徴量抽出 (LiteTrackNet)};
    B --> D{2b. コート特徴量抽出 (LiteTrackNet)};
    B --> E{2c. 選手特徴量抽出 (RT-DETR)};
    E --> F{2d. 姿勢特徴量抽出 (ViTPose)};
    C --> G[3. ボール軌道平滑化];
    G --> H{4. 特徴量統合 & パディング};
    D --> H;
    F --> H;
    H --> I{5. イベント検出 (EventTransformerV2)};
    I --> J{6a. イベント確率グラフ生成};
    I --> K{6b. 結果動画レンダリング};
    J --> L[グラフ画像 (.png)];
    K --> M[出力動画 (.mp4)];

    subgraph "ステージ1: 特徴抽出 (GPUバッチ処理)"
        B; C; D; E; F;
    end

    subgraph "ステージ2: 後処理 & 準備 (CPU)"
        G; H;
    end

    subgraph "ステージ3: イベント検出 (GPUチャンク処理)"
        I;
    end

    subgraph "ステージ4: 可視化"
        J; K;
    end
```

### 2.2. モジュール構成 (詳細版)
- **`demo/event.py`**: システム全体の処理フローを統括する、最も重要なスクリプト。モデルのロード、バッチ/チャンク処理、可視化までを実装。
- **`AppConfig`クラス**: チェックポイントのパス、画像サイズ、推論時の閾値など、すべての設定を管理するデータクラス。
- **`ModelLoader`クラス**: 5つのAIモデルと、それぞれに対応する画像前処理パイプライン(`albumentations`, `transformers.Processor`)をロードし、一元的に管理。
- **`BallTrajectorySmoother`クラス**: ボール検出結果の信頼性を向上させるための後処理クラス。確率によるフィルタリング、外れ値除去、欠損値補間を行う。
- **`src/{component}`**: 各解析コンポーネントのコアロジック。
    - **`models/`**: PyTorchモデルのアーキテクチャ定義 (`nn.Module`)。
    - **`dataset/`**: データセットの定義 (`torch.utils.data.Dataset`)。
    - **`lit_datamodule/`**: データ読み込みと前処理をカプセル化 (`pl.LightningDataModule`)。
    - **`lit_module/`**: 学習、検証、テストのロジックをカプセル化 (`pl.LightningModule`)。
    - **`api/`**: `train.py`など、外部からコンポーネントを操作するためのエントリーポイント。

### 2.3. 入出力仕様 (詳細版)
- **入力**:
    - MP4形式の動画ファイル。
- **出力**:
    - **イベント確率グラフ**: 各フレームにおける「ヒット」「バウンド」の発生確率を滑らかな曲線で描画したPNG画像。
    - **解析結果ビデオ**: 元の動画に以下の情報をオーバーレイ描画したMP4ファイル。
        - 平滑化されたボールの軌跡
        - イベント発生時のテキスト表示 ("HIT", "BOUNCE")

### 2.4. 処理フロー (詳細版)
`demo/event.py`における`full_analysis_pipeline`関数の処理フローは以下の通りです。

1.  **ステージ1: 特徴量抽出 (バッチ処理)**
    -   動画をフレームごとに読み込み、一定数（例：32フレーム）をメモリ上に溜める。
    -   溜まったフレームのバッチに対し、**ボール・コート・選手モデル**の推論を並列的に実行。
    -   選手検出結果（BBox）を使い、**姿勢推定モデル**の推論を実行。
    -   このバッチ処理を動画の終わりまで繰り返す。
2.  **ステージ1.5: ボール軌道平滑化**
    -   全フレームのボール検出結果（座標と確率）に対し、`BallTrajectorySmoother`を適用。
    -   確率の低い点を無効化し、物理的に不自然な跳び（外れ値）を除去後、欠損区間を線形補間する。
3.  **ステージ2: テンソル準備**
    -   全フレーム分の4種類の特徴量リストを、`EventTransformerV2`への入力形式に変換。
    -   1フレーム内の選手数が変動するため、シーケンス全体での最大選手数に合わせてゼロパディングを行い、テンソルの形状を `(B, T, P, D)` に統一する。
4.  **ステージ3: イベント検出 (チャンク処理)**
    -   長大な時系列特徴量テンソルを、GPUメモリに収まる固定長の**チャンク**（例：300フレーム）に分割。
    -   チャンクの境界での情報欠落を防ぐため、**オーバーラップ**（例：30フレーム）を持たせる。
    -   各チャンクを`EventTransformerV2`モデルに入力し、イベント確率を計算。
    -   全チャンクの結果を結合し、オーバーラップ部分を除去して、動画全体のイベント確率シーケンスを得る。
5.  **ステージ4 & 5: 結果生成とレンダリング**
    -   イベント確率からグラフ画像を生成。
    -   平滑化されたボール軌道とイベント検出結果を、元のフレームに描画し、出力ビデオを生成する。

---
## 3. 機械学習モデル詳細

### 3.1. 使用モデル
本システムでは、タスクの特性に応じて様々なモデルアーキテクチャを使い分けています。

| タスク | モデルアーキテクチャ | 主な特徴 |
| :--- | :--- | :--- |
| **ボール検出** | LiteTrackNet, Video Swin Transformer | 軽量U-Net型モデルと高精度Transformerモデル |
| **コート検出** | LiteTrackNet | ボール検出と類似のアーキテクチャをキーポイント検出に応用 |
| **選手検出** | RT-DETR | リアルタイム性能に優れたTransformerベースの物体検出モデル |
| **姿勢推定** | ViTPose | Vision Transformerベースの高精度な姿勢推定モデル |
| **イベント検出**| EventTransformerV2 | 複数モダリティの時系列データを統合するカスタムTransformer |

### 3.2. ボール検出モデル (`LiteTrackNet`)
- **アーキテクチャ**:
    - U-Netベースのエンコーダ・デコーダ構造。
    - **効率化技術**:
        - `DSConv`: Depthwise Separable Convolutionによりパラメータ数を削減。
        - `SE Block`: Squeeze-and-Excitationブロックでチャネル間の特徴量の重み付けを学習。
        - `PixelShuffle`: 効率的なアップサンプリング手法。
- **学習データ**:
    - 連続する3フレームの画像と、3フレーム目に対応するボール位置のヒートマップのペア。
- **学習プロセス**:
    - **損失関数**: `sigmoid_focal_loss` を使用。ヒートマップのように正解領域が非常に小さい（クラス不均衡な）場合に有効。
    - **オプティマイザ**: `AdamW`
    - **スケジューラ**: `CosineAnnealingLR` と線形ウォームアップを組み合わせ、安定した学習を実現。
    - **評価指標**: `Masked IoU` (Intersection over Union)
- **モデルの保存・読み込み**:
    - PyTorch Lightningのチェックポイント（`.ckpt`）として保存。
    - `LitLiteTracknetFocalLoss.load_from_checkpoint()` メソッドで読み込み可能。

### 3.3. コート検出モデル (`LiteTrackNet`)
- **アーキテクチャ**:
    - **ボール検出モデルと共通の`LiteTrackNet`アーキテクチャを採用**しており、コードの再利用性が高い。
    - **主な違い**:
        - **入力**: 単一のRGB画像（3チャンネル）。
        - **出力**: 15個のコートキーポイントに対応する15チャンネルのヒートマップ。
- **学習データ**:
    - 単一のフレーム画像と、それに対応する15チャンネルの目標ヒートマップのペア。各チャンネルが1つのキーポイントの位置を表す。
- **学習プロセス**:
    - ボール検出モデルと同様に、`Focal Loss`、`AdamW`、`CosineAnnealingLR`を使用。
- **後処理**:
    - 出力された15チャンネルのヒートマップそれぞれで最も確率の高いピクセルを検出し、15個のキーポイント座標 `(x, y)` を取得する。

### 3.4. 選手検出モデル (`RT-DETR`)
- **アーキテクチャ**:
    - Hugging Face `transformers`ライブラリの**RT-DETR (Real-Time Detection Transformer)** をベースにしています。
    - 事前学習済みモデル `PekingU/rtdetr_v2_r18vd` を利用し、テニス選手という単一クラスの検出に特化させています。
- **学習プロセス**:
    - **転移学習**: 大規模なデータセットで事前学習されたモデルをファインチューニングすることで、少ないデータでも高い性能を達成します。
    - **段階的学習**:
        1.  **初期エポック**: モデルの`backbone`（特徴抽出部）を凍結し、物体を検出する`head`部分のみを学習させます。
        2.  **後期エポック**: `backbone`の凍結を解除し、モデル全体を低い学習率で微調整します。
    - **差分学習率**: `backbone`と`head`で異なる学習率を適用し、学習の安定化を図っています。
- **後処理**:
    - モデルの出力は、`transformers`ライブラリの`RTDetrImageProcessor`を使用して、人間が解釈しやすいバウンディングボックスの座標と信頼度スコアのリストに変換されます。

### 3.5. 姿勢推定モデル (`ViTPose`)
- **アーキテクチャ**:
    - Hugging Face `transformers`ライブラリで提供されている**ViTPose (Vision Transformer for Pose Estimation)** を利用します。
    - ベースモデルは `usyd-community/vitpose-base-simple` です。
- **処理フロー**:
    - **選手検出モデルの出力（バウンディングボックス）が必須**です。
    - 検出された各選手の領域を画像から切り出し、`VitPose`モデルに入力することで、17点の骨格キーポイント（目、鼻、肩、肘など）の座標と信頼度スコアを取得します。
- **特徴**:
    - Vision Transformerをベースにしており、画像全体の文脈を捉える能力が高く、オクルージョン（隠れ）に強いとされています。

### 3.6. イベント検出モデル (`EventTransformerV2`)
- **アーキテクチャ**:
    - **本プロジェクトの核心となるマルチモーダル時系列Transformerモデル**です。
    - **入力**: 他の4モデル（ボール、コート、選手、姿勢）から抽出・後処理された時系列特徴量。
    - **構造**:
        1.  **モダリティ別埋め込み**: 4種類の入力特徴量を、それぞれ独立した線形層で高次元ベクトルに変換。
        2.  **Player Attention Pooling**: 複数選手の情報をAttention機構で一つのベクトルに集約。
        3.  **モダリティ別Transformer**: ボール、コート、選手の各時系列データに、それぞれ独立したTransformerエンコーダを適用し、時間的文脈を抽出。
        4.  **Cross-Attention融合**: 3つのTransformerの出力を、学習可能なクエリを用いたCross-Attentionで一つのベクトルに融合。
        5.  **分類ヘッド**: 最終的なベクトルを線形層に通し、「ヒット」「バウンド」の2クラスの確率を出力。
- **学習プロセス**:
    - **カスタム損失関数**:
        - **重み付きBCE**: イベントの有無（クラス不均衡）に応じてサンプルごとに損失の重みを変更。
        - **Clarity Regularizer**: 「ヒット」と「バウンド」が同時に高い確率で予測されることを防ぐ正則化項を導入。
- **特徴**:
    - 複数の異なる情報源を統合し、それらの時間的な関係性を捉えることで、単一の情報源だけでは困難な高度なイベント（例：ボールと選手のラケットが接触する「ヒット」）を検出します。

### 3.7. モデル連携とデータフロー
各モデルは独立しているわけではなく、下流のモデルが上流のモデルの出力を利用する依存関係にあります。

-   `選手検出` → `姿勢推定`: 選手検出モデルが出力したバウンディングボックスが、姿勢推定モデルの入力として必須です。
-   `ボール検出` + `コート検出` + `選手検出` + `姿勢推定` → `イベント検出`: 他の4モデルすべての後処理済み出力（時系列特徴量）が、イベント検出モデルの入力として必須です。

この連携を実現するため、`demo/event.py`では、まず上流の4モデルの推論を全フレームに対して行い、得られた特徴量リストを`prepare_tensors`関数で整形・パディングしてから、最終段のイベント検出モデルに入力しています。

---
## 4. データ処理パイプライン

### 4.1. データ拡張
学習時のデータ拡張は、`albumentations`ライブラリを用いて定義されています。`src/ball/api/train.py`の`hydra.utils.instantiate(cfg.litdatamodule)`で呼び出されるデータモジュール内で、以下のような拡張が設定されていると考えられます（`configs/train/ball/litdatamodule/*.yaml`参照）。
-   `Resize`: 画像を指定サイズ（例: 360x640）に統一。
-   `Normalize`: ピクセル値を平均0、標準偏差1付近に正規化。
-   （学習時のみ）`HorizontalFlip`, `RandomBrightnessContrast`など、モデルの汎化性能を高めるための拡張。

### 4.2. パディング処理 (`prepare_tensors`関数)
イベント検出モデルは、固定長のテンソルを入力として要求します。しかし、フレームごとに検出される選手の数は変動します。この問題を解決するため、以下のパディング処理が行われます。

1.  動画全体（シーケンス）で、1フレームあたりに検出された選手の最大数 `max_players` を特定します。
2.  各フレームについて、検出された選手数が `max_players` に満たない場合、その差の数だけ**ゼロベクトル**を追加します。
3.  これにより、`player_bbox_tensor`は `(1, T, max_players, 5)`、`player_pose_tensor`は `(1, T, max_players, 51)` という固定形状のテンソルになります。
4.  もし動画全体で選手が一人も検出されなかった場合でも、`max_players=0`の空のテンソルを作成し、処理が停止しないようになっています。

---
## 5. 実装詳細

### 5.1. 主要クラス・関数 (詳細版)
-   **`demo/event.py`**:
    -   `full_analysis_pipeline()`: 推論パイプライン全体を制御するメイン関数。
    -   `extract_features_batch()`: GPUのバッチ処理を活用して、動画から高速に特徴量を抽出する関数。
    -   `prepare_tensors()`: 抽出した特徴量リストを、パディングしてPyTorchテンソルに変換する関数。
    -   `render_output_video()`: 解析結果を元の動画フレームに描画する関数。
-   **`src/event/model/transformer_v2.py`**:
    -   `EventTransformerV2.forward()`: 4つのモダリティ（ボール、コート、選手BBox、選手姿勢）を入力とし、Attention PoolingとCross-Attentionを用いて情報を融合し、イベントのロジットを出力する、このシステムの核心部。
-   **`src/event/lit_module/lit_transformer_v2.py`**:
    -   `LitTransformerV2.custom_event_loss()`: 通常のBCE損失に加え、クラス不均衡を考慮したサンプル重み付けと、予測の明確性を促す「Clarity Regularizer」を組み合わせたカスタム損失関数。

### 5.2. 設定管理 (Hydra)
Hydraの設定は非常にモジュール化されています。例えば、ボール検出の学習(`src.ball.api.train`)では、`configs/train/ball/lite_tracknet_focal.yaml`がメインの設定ファイルとして読み込まれますが、その中身は以下のようになっています。

```yaml
# @package _global_

defaults:
  - trainer: default
  - litdatamodule: 3_frames_cat_last
  - litmodule: lite_tracknet
  - callbacks: default
  - _self_

seed: 42
checkpoint_dir: "checkpoints/ball"
```

-   `defaults`: 他のYAMLファイルをインクルードしています。これにより、`trainer`の設定は`trainer/default.yaml`から、`litdatamodule`の設定は`litdatamodule/3_frames_cat_last.yaml`から読み込まれます。
-   **動的な設定変更**: この構造のおかげで、コマンドラインから特定のコンポーネントの設定だけを簡単に切り替えることができます。
    ```bash
    # データモジュールだけを別の設定に切り替えて学習
    python -m src.ball.api.train litdatamodule=N_frames_stack_all
    ```

### 5.3. エラーハンドリング
- Pythonの標準的な`try...except`ブロックと`logging`モジュールを使用。
- 学習スクリプトでは、エラー発生時にスタックトレースを含む詳細なログを出力。

### 5.4. 最適化
- **GPU利用**: PyTorch Lightningを通じて、GPUアクセラレーションを標準でサポート。
- **並列処理**: `torch.utils.data.DataLoader`の`num_workers`により、データ読み込みを並列化。
- **メモリ効率化**: `LiteTrackNet`のような軽量モデルの採用や、`RT-DETR`の段階的学習により、限られた計算資源でも動作するように配慮。
- **混合精度計算**: `demo/event.py`の推論パイプラインでは、`torch.autocast`を用いて`bfloat16`形式での計算を行い、速度向上とメモリ削減を実現。
- **チャンク処理**: 長大な時系列データを扱うイベント検出モデルでは、入力をチャンクに分割して処理することで、VRAMの消費を抑える。

---
## 6. 使用方法・API仕様

### 6.1. インストール手順
1.  **リポジトリのクローン**:
    ```bash
    git clone <repository_url>
    cd tennis_systems
    ```
2.  **Python環境の構築**:
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```
3.  **依存関係のインストール**:
    `requirements.txt`が存在しないため、主要なライブラリを手動でインストールする必要があります。（これは改善点です）
    ```bash
    # PyTorch (CUDAバージョンに合わせて公式サイトからインストール)
    # pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

    pip install pytorch-lightning hydra-core omegaconf transformers opencv-python gradio fvcore pandas matplotlib
    ```

### 6.2. 基本的な使用方法
- **学習の実行**:
    ```bash
    # ボール検出モデルの学習 (デフォルト設定)
    python -m src.ball.api.train

    # 設定を変更して学習
    python -m src.ball.api.train litmodule=video_swin_transformer_focal trainer.max_epochs=10
    ```
- **推論の実行 (統合デモ)**:
    ```bash
    python demo/event.py
    ```
    これによりGradioベースのWeb UIが起動します。

### 6.3. 推論パイプラインの実行
このリポジトリの主要な使用方法は、`demo/event.py`を実行することです。
これによりGradioベースのWeb UIが起動し、ユーザーはビデオファイルをアップロードして、`full_analysis_pipeline`関数による完全な分析を実行できます。現時点では、このスクリプトが事実上の推論APIとなっています。

---
## 7. 実験結果・性能評価
（このセクションは、具体的な実験結果のデータがないため、ドキュメントの構成のみ示します）

### 7.1. 評価指標
- **ボール・コート検出**: Masked IoU, ヒートマップに対するFocal Loss
- **選手検出**: mAP (mean Average Precision), 各種損失（GIoU, L1, etc.）
- **イベント検出**: F1スコア, 適合率, 再現率, AUROC

### 7.2. 制限事項
- **カメラアングルへの依存**: 固定カメラからの映像を前提としており、大きく視点が動く映像には対応が困難。
- **オクルージョン**: 選手や他の物体によってボールが隠れると、検出が途切れる可能性がある。`BallTrajectorySmoother`である程度は緩和されるが、限界はある。
- **一般化性能**: 学習データに含まれないコートの照明条件や、特殊なカメラ設定では性能が低下する可能性がある。

---
## 8. 開発・運用ガイド

### 8.1. テスト
- **単体テスト・統合テスト**: `tests/`ディレクトリにテストコードが配置されている。`pytest`を使用して実行。
    ```bash
    pytest tests/infer_model_instantiate/
    ```

---
## 9. 今後の展開

### 9.1. 改善計画
- **依存関係管理の統一**: プロジェクトルートに`requirements.txt`や`pyproject.toml`を配置し、`pip install -e .`で開発環境を構築できるようにする。
- **推論APIの整備**: `src/{component}/api/infer.py`を整備し、学習済みモデルを使った推論をより簡単に行えるようにする。
- **ドキュメントの拡充**: 各設定項目の詳細な説明や、トラブルシューティングガイドを追加する。

### 9.2. 拡張可能性
- **他スポーツへの適用**: モデルアーキテクチャの一部（特に物体検出やイベント検出）は、他のスポーツ（サッカー、バスケットボールなど）の分析にも応用可能。
- **リアルタイム分析**: RT-DETRのようなリアルタイムモデルを中心にパイプラインを構築し、ライブ映像分析システムへ拡張。
