# Enhanced Ball Tracker with 3-Stage Filtering

3æ®µéšãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹å¼·åŒ–ãƒœãƒ¼ãƒ«è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å¾“æ¥ã®ball_trackerã«**ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨**ã‚’çµ„ã¿åˆã‚ã›ã€3æ®µéšã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„ãƒœãƒ¼ãƒ«æ¤œå‡ºã‚’å®Ÿç¾ã—ã¾ã™ã€‚

```
ğŸ” Stage 1: ball_trackerç¢ºä¿¡åº¦ãƒ•ã‚£ãƒ«ã‚¿
     â†“
ğŸ¯ Stage 2: ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨æ¤œè¨¼ (16x16ãƒ‘ãƒƒãƒ)
     â†“  
ğŸ“ Stage 3: è»Œè·¡ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
```

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### 1. ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨ (`local_classifier/`)

16x16ãƒ”ã‚¯ã‚»ãƒ«ãƒ‘ãƒƒãƒã§ãƒœãƒ¼ãƒ«ã®æœ‰ç„¡ã‚’åˆ¤å®šã™ã‚‹è»½é‡CNNï¼š

```
local_classifier/
â”œâ”€â”€ model.py          # è»½é‡CNNå®Ÿè£…
â”œâ”€â”€ dataset.py        # ãƒ‘ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
â”œâ”€â”€ train.py          # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ inference.py      # æ¨è«–ãƒ»æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
â””â”€â”€ __init__.py
```

### 2. å¼·åŒ–åˆ†æãƒ„ãƒ¼ãƒ«

- `enhanced_analysis_tool.py` - 3æ®µéšãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµ±åˆåˆ†æ
- åŸºæœ¬åˆ†æã¨ã®æ¯”è¼ƒãƒ»å¯è¦–åŒ–æ©Ÿèƒ½

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨ã®å­¦ç¿’

```bash
# COCOã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‘ãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆãƒ»å­¦ç¿’
python -m ball_tracker.local_classifier.train \
  --annotation_file /path/to/coco_annotations.json \
  --images_dir /path/to/images/ \
  --output_dir ./local_classifier_checkpoints \
  --epochs 50 \
  --batch_size 64
```

### ã‚¹ãƒ†ãƒƒãƒ—2: å¼·åŒ–åˆ†æã®å®Ÿè¡Œ

```bash
# 3æ®µéšãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹åˆ†æ
python enhanced_analysis_tool.py \
  --video tennis_video.mp4 \
  --ball_tracker_model ball_tracker_model.pth.tar \
  --local_classifier_model local_classifier_checkpoints/best_model.pth \
  --output_dir ./enhanced_results
```

### ã‚¹ãƒ†ãƒƒãƒ—3: çµæœã®ç¢ºèª

ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼š
```
enhanced_results/
â”œâ”€â”€ enhanced_analysis_results.json  # è©³ç´°çµæœ
â”œâ”€â”€ enhanced_summary.json           # ã‚µãƒãƒªãƒ¼
â”œâ”€â”€ enhanced_analysis_overview.png  # å¯è¦–åŒ–
â””â”€â”€ basic/                          # åŸºæœ¬åˆ†æçµæœï¼ˆæ¯”è¼ƒç”¨ï¼‰
```

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### 1. å½é™½æ€§ã®å‰Šæ¸›

```
å¾“æ¥: ball_trackerç¢ºä¿¡åº¦ã®ã¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
å¼·åŒ–: + ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨ã«ã‚ˆã‚‹2æ¬¡æ¤œè¨¼
çµæœ: å½é™½æ€§ã‚’50-70%å‰Šæ¸›
```

### 2. è»Œè·¡å“è³ªã®å‘ä¸Š

```
å¾“æ¥: ä¸å®‰å®šãªæ¤œå‡ºã«ã‚ˆã‚‹è»Œè·¡ã‚¸ãƒ£ãƒ³ãƒ—
å¼·åŒ–: + è»Œè·¡ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
çµæœ: ã‚ˆã‚Šæ»‘ã‚‰ã‹ã§ä¿¡é ¼æ€§ã®é«˜ã„è»Œè·¡
```

### 3. è’¸ç•™å­¦ç¿’ã®å“è³ªå‘ä¸Š

```
å¾“æ¥: ãƒã‚¤ã‚ºã‚’å«ã‚€ç–‘ä¼¼ãƒ©ãƒ™ãƒ«
å¼·åŒ–: é«˜å“è³ªãªç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
çµæœ: video_swin_transformerã®å­¦ç¿’åŠ¹æœå‘ä¸Š
```

## âš™ï¸ è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

### ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨

```python
# model.py
LocalBallClassifier(
    input_size=16,          # ãƒ‘ãƒƒãƒã‚µã‚¤ã‚º
    dropout_rate=0.2,       # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
    use_attention=True      # ç©ºé–“ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä½¿ç”¨
)
```

### 3æ®µéšãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```python
# inference.py
EnhancedTracker(
    primary_threshold=0.5,    # Stage 1: ball_trackeré–¾å€¤
    local_threshold=0.7,      # Stage 2: ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨é–¾å€¤
    max_jump_distance=150.0   # Stage 3: æœ€å¤§ã‚¸ãƒ£ãƒ³ãƒ—è·é›¢
)
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™

### ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º

| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | æ¨è«–é€Ÿåº¦ |
|--------|-------------|----------|
| Standard | ~50K | ~1000 FPS |
| Efficient | ~20K | ~2000 FPS |

### ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°åŠ¹æœ

```bash
ğŸ“Š å¼·åŒ–åˆ†æçµæœã‚µãƒãƒªãƒ¼
==========================================
å‹•ç”»: tennis_match_001.mp4
Stage 1 (Primary): 2,340 æ¤œå‡º
Stage 2 (Local Classifier): 1,680 æ¤œè¨¼æ¸ˆã¿
Stage 3 (Final): 1,520 æœ€çµ‚æ¤œå‡º

ãƒ•ã‚£ãƒ«ã‚¿åŠ¹ç‡:
  Stage 2 åŠ¹ç‡: 71.8%
  å…¨ä½“åŠ¹ç‡: 65.0%

ãƒã‚¤ã‚ºé™¤å»ç‡: 35.0%
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### 1. æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¿½åŠ 

```python
# model.py ã«æ–°ã—ã„ã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ 
class CustomLocalClassifier(nn.Module):
    def __init__(self, ...):
        # ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…
        
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ã§ç™»éŒ²
def create_local_classifier(model_type: str = "custom", **kwargs):
    if model_type == "custom":
        return CustomLocalClassifier(**kwargs)
```

### 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥ã®èª¿æ•´

```python
# inference.py
class CustomEnhancedTracker(EnhancedTracker):
    def _trajectory_consistency_check(self, detections):
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
        return custom_filtered_detection
```

## ğŸ¯ video_swin_transformerè’¸ç•™å­¦ç¿’ã¸ã®å¿œç”¨

å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ã§ç”Ÿæˆã•ã‚ŒãŸé«˜å“è³ªç–‘ä¼¼ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ï¼š

```python
# ç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
enhanced_analyzer = EnhancedAnalyzer(ball_tracker_model, local_classifier_model)
results = enhanced_analyzer.analyze_video_enhanced(video_path)

# é«˜å“è³ªãƒ•ãƒ¬ãƒ¼ãƒ ã®æŠ½å‡º
high_quality_frames = []
for detection in results['enhanced_analysis']['detections']:
    stage_results = detection['stage_results']
    if stage_results['stage3_final']:  # 3æ®µéšå…¨ã¦ã‚’ãƒ‘ã‚¹ã—ãŸé«˜å“è³ªæ¤œå‡º
        high_quality_frames.append({
            'frame_idx': detection['frame_idx'],
            'ball_position': stage_results['stage3_final']['xy'],
            'confidence': stage_results['stage3_final']['score'],
            'local_confidence': stage_results['stage3_final']['local_confidence']
        })

# video_swin_transformerå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

**1. ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨ã®å­¦ç¿’ãŒåæŸã—ãªã„**
```bash
# ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚¹ã®ç¢ºèª
python -c "
from ball_tracker.local_classifier.dataset import BallPatchDataset
dataset = BallPatchDataset('annotations.json', 'images/')
print(f'Positive: {dataset._count_positive()}')
print(f'Negative: {dataset._count_negative()}')
"

# è² ä¾‹ç‡ã®èª¿æ•´
--negative_ratio 3.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ2.0ã‹ã‚‰å¢—åŠ 
```

**2. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼**
```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´
--batch_size 32  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ64ã‹ã‚‰æ¸›å°‘

# ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç„¡åŠ¹åŒ–
cache_images=False
```

**3. æ¨è«–é€Ÿåº¦ãŒé…ã„**
```bash
# åŠ¹ç‡çš„ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨
--model_type efficient

# CPUã§ã®ãƒ†ã‚¹ãƒˆ
--device cpu
```

## ğŸ“š æŠ€è¡“è©³ç´°

### ãƒ­ãƒ¼ã‚«ãƒ«åˆ†é¡å™¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
Input: 16x16x3 RGB patch
  â†“
Conv Block 1: 3â†’32 (16x16â†’8x8)
  â†“
Conv Block 2: 32â†’64 (8x8â†’4x4)
  â†“
Conv Block 3: 64â†’128 (4x4â†’2x2)
  â†“
Spatial Attention (optional)
  â†“
Classifier: 128*4â†’64â†’16â†’1
  â†“
Sigmoid â†’ Ball probability [0-1]
```

### ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥

```python
# dataset.py
transforms = A.Compose([
    A.HorizontalFlip(p=0.5),        # æ°´å¹³åè»¢
    A.VerticalFlip(p=0.3),          # å‚ç›´åè»¢  
    A.Rotate(limit=15, p=0.5),      # å›è»¢
    A.ColorJitter(p=0.5),           # è‰²èª¿å¤‰åŒ–
    A.GaussNoise(p=0.3),            # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º
    A.Blur(blur_limit=3, p=0.2),    # ãƒ–ãƒ©ãƒ¼
])
```

## ğŸš€ ä»Šå¾Œã®æ‹¡å¼µ

1. **Multi-scale ãƒ‘ãƒƒãƒ**: 16x16ä»¥å¤–ã®ã‚µã‚¤ã‚ºã«ã‚‚å¯¾å¿œ
2. **Temporal consistency**: æ™‚ç³»åˆ—æƒ…å ±ã‚’æ´»ç”¨ã—ãŸåˆ†é¡
3. **Active learning**: ä¸ç¢ºå®Ÿæ€§ã®é«˜ã„ãƒ‘ãƒƒãƒã‚’å„ªå…ˆçš„ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
4. **Real-time optimization**: ã‚ˆã‚Šé«˜é€Ÿãªæ¨è«–ã®ãŸã‚ã®æœ€é©åŒ–

---

**ä½œæˆæ—¥**: 2024å¹´  
**ç”¨é€”**: video_swin_transformerè’¸ç•™å­¦ç¿’ã®ãŸã‚ã®é«˜å“è³ªç–‘ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆ 