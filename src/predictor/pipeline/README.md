# ğŸš€ Parallel Video Processing Pipeline

é«˜åŠ¹ç‡ãƒ†ãƒ‹ã‚¹ãƒœãƒ¼ãƒ«æ¤œå‡ºãƒ»å¯è¦–åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚ŠGPUåˆ©ç”¨ç‡ã‚’æœ€å¤§åŒ–ã—ã€ãƒ†ãƒ‹ã‚¹å‹•ç”»ã‹ã‚‰ã®ãƒœãƒ¼ãƒ«æ¤œå‡ºã¨å¯è¦–åŒ–ã‚’é«˜é€Ÿã§å®Ÿè¡Œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

### ğŸ¯ ä¸»ãªç‰¹å¾´

- **ğŸ”„ ä¸¦åˆ—å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: GPUå¾…æ©Ÿæ™‚é–“ã‚’æœ€å°åŒ–
- **âš¡ é«˜é€Ÿå‡¦ç†**: å¾“æ¥æ¯”3-5å€ã®å‡¦ç†é€Ÿåº¦å‘ä¸Š
- **ğŸ¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾å¿œ**: ãƒ©ã‚¤ãƒ–é…ä¿¡ã«ã‚‚å¯¾å¿œå¯èƒ½
- **ğŸ’¾ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: å¤§å®¹é‡å‹•ç”»ã‚‚å®‰å…¨ã«å‡¦ç†
- **ğŸ¨ é«˜å“è³ªå¯è¦–åŒ–**: è»Œè·¡è¿½è·¡ãƒ»äºˆæ¸¬è¡¨ç¤ºå¯¾å¿œ

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frame Reader   â”‚ -> â”‚  Preprocessor    â”‚ -> â”‚ Inference Queue â”‚
â”‚     Thread      â”‚    â”‚     Thread       â”‚    â”‚   (GPU Ready)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚ Visualization   â”‚ <- â”‚  Postprocessor   â”‚ <----------â”˜
â”‚     Thread      â”‚    â”‚     Thread       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ <- â”‚  GPU Inference  â”‚
                                                â”‚     Thread      â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ã‚¹ãƒ¬ãƒƒãƒ‰æ§‹æˆ

1. **Frame Reader Thread**: å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
2. **Preprocessor Threads**: ãƒ•ãƒ¬ãƒ¼ãƒ å‰å‡¦ç†ï¼ˆè¤‡æ•°ä¸¦åˆ—ï¼‰
3. **GPU Inference Thread**: GPUã§ã®æ¨è«–å®Ÿè¡Œ
4. **Postprocessor Threads**: å¾Œå‡¦ç†ãƒ»æ¤œå‡ºçµæœç”Ÿæˆ
5. **Visualization Thread**: å¯è¦–åŒ–ãƒ»å‹•ç”»å‡ºåŠ›
6. **Monitor Thread**: æ€§èƒ½ç›£è¦–ãƒ»ãƒ­ã‚°å‡ºåŠ›

### ã‚­ãƒ¥ãƒ¼ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

- **Frame Queue**: èª­ã¿è¾¼ã¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°
- **Tensor Queue**: å‰å‡¦ç†æ¸ˆã¿ãƒ†ãƒ³ã‚½ãƒ«ã®è“„ç©ï¼ˆGPUå¾…æ©Ÿæ™‚é–“å‰Šæ¸›ï¼‰
- **Result Queue**: æ¨è«–çµæœã®ä¸€æ™‚ä¿å­˜
- **Render Queue**: å¯è¦–åŒ–å¾…ã¡ãƒ‡ãƒ¼ã‚¿

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ç”¨

```python
from src.predictor.pipeline import VideoPipeline

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
pipeline = VideoPipeline()

# æ¤œå‡ºå™¨è¨­å®š
detector_config = {
    "model_type": "wasb_sbdt",
    "model_path": "checkpoints/model.pth",
    "device": "cuda"
}

# å‹•ç”»å‡¦ç†å®Ÿè¡Œ
result = pipeline.process_video(
    video_path="input.mp4",
    detector_config=detector_config,
    output_path="output.mp4"
)

print(f"å‡¦ç†å®Œäº†: {result['average_fps']:.2f} FPS")
```

### é«˜æ€§èƒ½è¨­å®š

```python
from src.predictor.pipeline import VideoPipeline, HIGH_PERFORMANCE_CONFIG

# é«˜æ€§èƒ½è¨­å®šã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ
pipeline = VideoPipeline(HIGH_PERFORMANCE_CONFIG)

# ã‚«ã‚¹ã‚¿ãƒ å¯è¦–åŒ–è¨­å®š
from src.predictor.visualization import VisualizationConfig
vis_config = VisualizationConfig(
    ball_radius=12,
    trajectory_length=25,
    enable_smoothing=True,
    enable_prediction=True
)

result = pipeline.process_video(
    video_path="input.mp4",
    detector_config=detector_config,
    output_path="output.mp4",
    visualization_config=vis_config
)
```

### éåŒæœŸå‡¦ç†

```python
# éåŒæœŸå‡¦ç†é–‹å§‹
async_result = pipeline.process_video_async(
    video_path="input.mp4",
    detector_config=detector_config,
    output_path="output.mp4"
)

# é€²æ—ç›£è¦–
while not async_result.is_completed():
    progress = async_result.get_progress()
    print(f"é€²æ—: {progress*100:.1f}%")
    time.sleep(0.5)

# çµæœå–å¾—
result = async_result.get_result()
```

## âš™ï¸ è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

### PipelineConfig ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```python
from src.predictor.pipeline import PipelineConfig

config = PipelineConfig(
    # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
    frame_buffer_size=30,        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡
    tensor_buffer_size=15,       # ãƒ†ãƒ³ã‚½ãƒ«ãƒãƒƒãƒ•ã‚¡
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    num_preprocessing_threads=2, # å‰å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    gpu_batch_size=4,           # GPUãƒãƒƒãƒã‚µã‚¤ã‚º
    
    # æœ€é©åŒ–è¨­å®š
    enable_memory_optimization=True,
    enable_cpu_offload=False,
    
    # ãƒ‡ãƒãƒƒã‚°
    enable_profiling=True,
    log_queue_sizes=True
)
```

### ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š

```python
from src.predictor.pipeline import (
    HIGH_PERFORMANCE_CONFIG,    # æœ€é«˜æ€§èƒ½
    MEMORY_EFFICIENT_CONFIG,    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡
    REALTIME_CONFIG,           # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ 
    DEBUG_CONFIG               # ãƒ‡ãƒãƒƒã‚°ç”¨
)
```

## ğŸ“Š æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```python
# æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
results = pipeline.benchmark_performance(
    video_path="test_video.mp4",
    detector_config=detector_config
)

for config_name, result in results.items():
    print(f"{config_name}: {result['average_fps']:.2f} FPS")
```

## ğŸ¨ å¯è¦–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³

```python
from src.predictor.visualization import VisualizationConfig

vis_config = VisualizationConfig(
    # çƒä½“æç”»
    ball_radius=10,
    ball_color=(0, 0, 255),     # BGRè‰²æŒ‡å®š
    
    # è»Œè·¡è¡¨ç¤º
    show_trajectory=True,
    trajectory_length=20,
    trajectory_color=(0, 255, 255),
    
    # é«˜åº¦æ©Ÿèƒ½
    enable_smoothing=True,      # ä½ç½®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    enable_prediction=True,     # äºˆæ¸¬è¡¨ç¤º
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    confidence_threshold=0.3
)
```

## ğŸ“ˆ æ€§èƒ½æœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ

### GPUåˆ©ç”¨ç‡æœ€å¤§åŒ–
- `tensor_buffer_size`ã‚’å¤§ããã—ã¦GPUå¾…æ©Ÿæ™‚é–“ã‚’å‰Šæ¸›
- `gpu_batch_size`ã‚’èª¿æ•´ã—ã¦GPUãƒ¡ãƒ¢ãƒªã‚’æœ‰åŠ¹æ´»ç”¨
- `num_preprocessing_threads`ã‚’å¢—ã‚„ã—ã¦å‰å‡¦ç†ã‚’ä¸¦åˆ—åŒ–

### ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
- `enable_memory_optimization=True`ã§è‡ªå‹•æœ€é©åŒ–
- `enable_cpu_offload=True`ã§GPUãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„
- `frame_buffer_size`ã‚’èª¿æ•´ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ¶å¾¡

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
- `enable_frame_skipping=True`ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
- `frame_skip_interval`ã§å‡¦ç†é–“éš”èª¿æ•´
- å°ã•ãª`buffer_size`ã§é…å»¶ã‚’æœ€å°åŒ–

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **GPU OutOfMemory**
   - `gpu_batch_size`ã‚’å°ã•ãã™ã‚‹
   - `enable_cpu_offload=True`ã‚’è¨­å®š
   - `max_gpu_memory_fraction`ã‚’èª¿æ•´

2. **å‡¦ç†ãŒé…ã„**
   - `tensor_buffer_size`ã‚’å¢—ã‚„ã™
   - `num_preprocessing_threads`ã‚’å¢—ã‚„ã™
   - GPUãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

3. **ãƒ¡ãƒ¢ãƒªä¸è¶³**
   - `MEMORY_EFFICIENT_CONFIG`ã‚’ä½¿ç”¨
   - `frame_buffer_size`ã‚’å°ã•ãã™ã‚‹
   - `enable_memory_optimization=True`ã‚’è¨­å®š

### ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰

```python
from src.predictor.pipeline import DEBUG_CONFIG

pipeline = VideoPipeline(DEBUG_CONFIG)
# è©³ç´°ãªãƒ­ã‚°ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æƒ…å ±ãŒå‡ºåŠ›ã•ã‚Œã‚‹
```

## ğŸ“ ä¾‹ã¨ã‚µãƒ³ãƒ—ãƒ«

è©³ç´°ãªä½¿ç”¨ä¾‹ã¯`examples.py`ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š

```python
from src.predictor.pipeline import examples

# åŸºæœ¬å‡¦ç†ä¾‹
examples.example_basic_processing()

# é«˜æ€§èƒ½å‡¦ç†ä¾‹
examples.example_high_performance_processing()

# éåŒæœŸå‡¦ç†ä¾‹
examples.example_async_processing()
```

## ğŸ”— é–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

- `src.predictor.ball`: ãƒœãƒ¼ãƒ«æ¤œå‡ºå™¨
- `src.predictor.visualization`: å¯è¦–åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- `src.predictor.base`: ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯ç ”ç©¶ãƒ»é–‹ç™ºç›®çš„ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚ 