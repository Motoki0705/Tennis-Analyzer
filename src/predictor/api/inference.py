#!/usr/bin/env python3
"""
Tennis Ball Detection Inference API
===================================

ğŸ¾ ãƒ†ãƒ‹ã‚¹ãƒœãƒ¼ãƒ«æ¤œå‡ºæ¨è«–çµ±åˆã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ãƒ†ãƒ‹ã‚¹å‹•ç”»ã‹ã‚‰ã®ãƒœãƒ¼ãƒ«æ¤œå‡ºã€å¯è¦–åŒ–ã€çµ±è¨ˆå‡ºåŠ›ã¾ã§ã‚’
ãƒ¯ãƒ³ã‚¹ãƒˆãƒƒãƒ—ã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚

Features:
- ğŸ¤– è¤‡æ•°æ¤œå‡ºå™¨å¯¾å¿œ (LiteTrackNet, WASB-SBDT)
- ğŸš€ ä¸¦åˆ—å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- ğŸ¨ é«˜å“è³ªå¯è¦–åŒ–
- ğŸ“Š çµ±è¨ˆæƒ…å ±å‡ºåŠ›
- âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã€œãƒãƒƒãƒå‡¦ç†

Usage:
    python -m src.predictor.api.inference \
        --video input.mp4 \
        --output output.mp4 \
        --model_path checkpoints/model.ckpt \
        --model_type lite_tracknet \
        --config high_performance

Examples:
    # åŸºæœ¬å®Ÿè¡Œ
    python -m src.predictor.api.inference \
        --video tennis_match.mp4 \
        --output annotated_match.mp4 \
        --model_path checkpoints/lite_tracknet.ckpt

    # é«˜æ€§èƒ½ä¸¦åˆ—å‡¦ç†
    python -m src.predictor.api.inference \
        --video long_match.mp4 \
        --output result.mp4 \
        --model_path models/wasb_sbdt.pth \
        --model_type wasb_sbdt \
        --config high_performance \
        --batch_size 16 \
        --num_workers 8

    # ã‚«ã‚¹ã‚¿ãƒ å¯è¦–åŒ–
    python -m src.predictor.api.inference \
        --video input.mp4 \
        --output stylized.mp4 \
        --model_path model.ckpt \
        --ball_radius 15 \
        --trajectory_length 30 \
        --enable_prediction \
        --stats_output stats.json
"""

import argparse
import json
import logging
import os
import sys
import time
from pathlib import Path
from typing import Dict, Any, Optional

import torch

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.predictor import (
    VideoPipeline, 
    create_ball_detector,
    VisualizationConfig,
    HIGH_PERFORMANCE_CONFIG,
    MEMORY_EFFICIENT_CONFIG,
    REALTIME_CONFIG,
    DEBUG_CONFIG
)
from src.utils.logging_utils import setup_logging


def setup_arguments() -> argparse.ArgumentParser:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è¨­å®š"""
    parser = argparse.ArgumentParser(
        description="Tennis Ball Detection Inference System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # === å…¥å‡ºåŠ›è¨­å®š ===
    io_group = parser.add_argument_group('Input/Output Settings')
    io_group.add_argument(
        '--video', '-v', type=str, required=True,
        help='å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    io_group.add_argument(
        '--output', '-o', type=str, required=True,
        help='å‡ºåŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    io_group.add_argument(
        '--stats_output', type=str,
        help='çµ±è¨ˆæƒ…å ±å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (JSONå½¢å¼)'
    )
    
    # === ãƒ¢ãƒ‡ãƒ«è¨­å®š ===
    model_group = parser.add_argument_group('Model Settings')
    model_group.add_argument(
        '--model_path', '-m', type=str, required=True,
        help='ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.ckpt ã¾ãŸã¯ .pth)'
    )
    model_group.add_argument(
        '--model_type', type=str, choices=['lite_tracknet', 'wasb_sbdt', 'auto'],
        default='auto',
        help='ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— (auto: æ‹¡å¼µå­ã‹ã‚‰è‡ªå‹•åˆ¤å®š)'
    )
    model_group.add_argument(
        '--config_path', type=str,
        help='ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    model_group.add_argument(
        '--device', type=str, choices=['auto', 'cpu', 'cuda'],
        default='auto',
        help='å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹ (auto: GPUè‡ªå‹•æ¤œå‡º)'
    )
    
    # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š ===
    pipeline_group = parser.add_argument_group('Pipeline Settings')
    pipeline_group.add_argument(
        '--config', type=str, 
        choices=['high_performance', 'memory_efficient', 'realtime', 'debug'],
        default='high_performance',
        help='ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆ'
    )
    pipeline_group.add_argument(
        '--batch_size', type=int, default=8,
        help='ãƒãƒƒãƒã‚µã‚¤ã‚º'
    )
    pipeline_group.add_argument(
        '--num_workers', type=int, default=4,
        help='ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰æ•°'
    )
    pipeline_group.add_argument(
        '--queue_size', type=int, default=100,
        help='ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º'
    )
    
    # === å¯è¦–åŒ–è¨­å®š ===
    vis_group = parser.add_argument_group('Visualization Settings')
    vis_group.add_argument(
        '--ball_radius', type=int, default=8,
        help='ãƒœãƒ¼ãƒ«æç”»åŠå¾„'
    )
    vis_group.add_argument(
        '--trajectory_length', type=int, default=20,
        help='è»Œè·¡è¡¨ç¤ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°'
    )
    vis_group.add_argument(
        '--enable_smoothing', action='store_true',
        help='ä½ç½®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœ‰åŠ¹åŒ–'
    )
    vis_group.add_argument(
        '--enable_prediction', action='store_true',
        help='ä½ç½®äºˆæ¸¬è¡¨ç¤ºæœ‰åŠ¹åŒ–'
    )
    vis_group.add_argument(
        '--confidence_threshold', type=float, default=0.5,
        help='ä¿¡é ¼åº¦é–¾å€¤'
    )
    
    # === ã‚·ã‚¹ãƒ†ãƒ è¨­å®š ===
    sys_group = parser.add_argument_group('System Settings')
    sys_group.add_argument(
        '--log_level', type=str, 
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«'
    )
    sys_group.add_argument(
        '--async_processing', action='store_true',
        help='éåŒæœŸå‡¦ç†ãƒ¢ãƒ¼ãƒ‰'
    )
    sys_group.add_argument(
        '--progress_interval', type=float, default=1.0,
        help='é€²æ—è¡¨ç¤ºé–“éš”ï¼ˆç§’ï¼‰'
    )
    
    return parser


def get_pipeline_config(config_name: str, args: argparse.Namespace) -> Dict[str, Any]:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šå–å¾—"""
    # ãƒ™ãƒ¼ã‚¹è¨­å®šé¸æŠ
    if config_name == 'high_performance':
        base_config = HIGH_PERFORMANCE_CONFIG
    elif config_name == 'memory_efficient':
        base_config = MEMORY_EFFICIENT_CONFIG
    elif config_name == 'realtime':
        base_config = REALTIME_CONFIG
    elif config_name == 'debug':
        base_config = DEBUG_CONFIG
    else:
        raise ValueError(f"Unknown config: {config_name}")
    
    # ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºé©ç”¨
    config = base_config.copy()
    if args.batch_size != 8:
        config['batch_size'] = args.batch_size
    if args.num_workers != 4:
        config['num_workers'] = args.num_workers
    if args.queue_size != 100:
        config['queue_size'] = args.queue_size
        
    return config


def get_detector_config(args: argparse.Namespace) -> Dict[str, Any]:
    """æ¤œå‡ºå™¨è¨­å®šå–å¾—"""
    # ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤å®š
    if args.model_type == 'auto':
        if args.model_path.endswith('.ckpt'):
            model_type = 'lite_tracknet'
        elif args.model_path.endswith('.pth'):
            model_type = 'wasb_sbdt'
        else:
            raise ValueError(f"Cannot auto-detect model type from: {args.model_path}")
    else:
        model_type = args.model_type
    
    config = {
        'model_path': args.model_path,
        'model_type': model_type,
        'device': device,
    }
    
    if args.config_path:
        config['config_path'] = args.config_path
        
    return config


def get_visualization_config(args: argparse.Namespace) -> VisualizationConfig:
    """å¯è¦–åŒ–è¨­å®šå–å¾—"""
    return VisualizationConfig(
        ball_radius=args.ball_radius,
        trajectory_length=args.trajectory_length,
        enable_smoothing=args.enable_smoothing,
        enable_prediction=args.enable_prediction,
        confidence_threshold=args.confidence_threshold
    )


def calculate_statistics(result: Dict[str, Any]) -> Dict[str, Any]:
    """çµ±è¨ˆæƒ…å ±è¨ˆç®—"""
    stats = {
        'processing_info': {
            'total_frames': result.get('total_frames', 0),
            'processed_frames': result.get('processed_frames', 0),
            'processing_time': result.get('processing_time', 0.0),
            'average_fps': result.get('average_fps', 0.0),
        },
        'detection_stats': {
            'total_detections': 0,
            'frames_with_detection': 0,
            'average_confidence': 0.0,
            'detection_rate': 0.0,
        },
        'performance_stats': {
            'gpu_utilization': result.get('gpu_utilization', 0.0),
            'memory_usage': result.get('memory_usage', 0.0),
            'queue_efficiency': result.get('queue_efficiency', 0.0),
        }
    }
    
    # æ¤œå‡ºçµ±è¨ˆè¨ˆç®—
    detections = result.get('detections', {})
    if detections:
        total_detections = sum(len(det_list) for det_list in detections.values())
        frames_with_detection = sum(1 for det_list in detections.values() if det_list)
        
        all_confidences = []
        for det_list in detections.values():
            all_confidences.extend([det[2] for det in det_list if len(det) > 2])
        
        stats['detection_stats'].update({
            'total_detections': total_detections,
            'frames_with_detection': frames_with_detection,
            'average_confidence': sum(all_confidences) / len(all_confidences) if all_confidences else 0.0,
            'detection_rate': frames_with_detection / len(detections) if detections else 0.0,
        })
    
    return stats


def save_statistics(stats: Dict[str, Any], output_path: str):
    """çµ±è¨ˆæƒ…å ±ä¿å­˜"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    logging.info(f"çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: {output_path}")


def display_progress(result, progress_interval: float):
    """é€²æ—è¡¨ç¤º"""
    while not result.is_completed():
        progress = result.get_progress()
        current_fps = result.get_current_fps()
        logging.info(f"é€²æ—: {progress*100:.1f}% | ç¾åœ¨ã®FPS: {current_fps:.1f}")
        time.sleep(progress_interval)


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    # å¼•æ•°è§£æ
    parser = setup_arguments()
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    setup_logging(level=args.log_level)
    logging.info("ğŸ¾ Tennis Ball Detection Inference System é–‹å§‹")
    
    try:
        # å…¥åŠ›æ¤œè¨¼
        if not os.path.exists(args.video):
            raise FileNotFoundError(f"å…¥åŠ›å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.video}")
        
        if not os.path.exists(args.model_path):
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.model_path}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(os.path.dirname(args.output), exist_ok=True)
        
        # è¨­å®šå–å¾—
        pipeline_config = get_pipeline_config(args.config, args)
        detector_config = get_detector_config(args)
        vis_config = get_visualization_config(args)
        
        logging.info(f"å…¥åŠ›å‹•ç”»: {args.video}")
        logging.info(f"å‡ºåŠ›å‹•ç”»: {args.output}")
        logging.info(f"ãƒ¢ãƒ‡ãƒ«: {detector_config['model_type']} ({args.model_path})")
        logging.info(f"ãƒ‡ãƒã‚¤ã‚¹: {detector_config['device']}")
        logging.info(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š: {args.config}")
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ
        pipeline = VideoPipeline(pipeline_config)
        
        # å‡¦ç†å®Ÿè¡Œ
        start_time = time.time()
        
        if args.async_processing:
            # éåŒæœŸå‡¦ç†
            logging.info("éåŒæœŸå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...")
            result = pipeline.process_video_async(
                video_path=args.video,
                detector_config=detector_config,
                output_path=args.output,
                vis_config=vis_config
            )
            
            # é€²æ—è¡¨ç¤º
            display_progress(result, args.progress_interval)
            final_result = result.get_result()
            
        else:
            # åŒæœŸå‡¦ç†
            logging.info("åŒæœŸå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...")
            final_result = pipeline.process_video(
                video_path=args.video,
                detector_config=detector_config,
                output_path=args.output,
                vis_config=vis_config
            )
        
        processing_time = time.time() - start_time
        
        # çµæœè¡¨ç¤º
        logging.info("ğŸ¯ å‡¦ç†å®Œäº†!")
        logging.info(f"å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        logging.info(f"å¹³å‡FPS: {final_result.get('average_fps', 0):.2f}")
        logging.info(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {final_result.get('total_frames', 0)}")
        logging.info(f"æ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {sum(1 for det_list in final_result.get('detections', {}).values() if det_list)}")
        
        # çµ±è¨ˆæƒ…å ±ä¿å­˜
        if args.stats_output:
            stats = calculate_statistics(final_result)
            save_statistics(stats, args.stats_output)
        
        logging.info(f"å‡ºåŠ›å‹•ç”»: {args.output}")
        
    except Exception as e:
        logging.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main() 