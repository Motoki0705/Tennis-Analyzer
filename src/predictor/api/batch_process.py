#!/usr/bin/env python3
"""
Tennis Ball Detection Batch Processing API
==========================================

ğŸ¾ ãƒ†ãƒ‹ã‚¹ãƒœãƒ¼ãƒ«æ¤œå‡ºãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 

è¤‡æ•°ã®ãƒ†ãƒ‹ã‚¹å‹•ç”»ã‚’åŠ¹ç‡çš„ã«ä¸€æ‹¬å‡¦ç†ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚
ä¸¦åˆ—å‡¦ç†ã€é€²æ—ç®¡ç†ã€ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

Features:
- ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å‡¦ç†
- ğŸ”„ ä¸¦åˆ—ãƒãƒƒãƒå‡¦ç†
- ğŸ“Š çµ±ä¸€çµ±è¨ˆæƒ…å ±
- ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ»ç¶šè¡Œ
- ğŸ“ˆ è©³ç´°é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ

Usage:
    python -m src.predictor.api.batch_process \
        --input_dir videos/ \
        --output_dir results/ \
        --model_path checkpoints/model.ckpt \
        --parallel_jobs 4

Examples:
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å‡¦ç†
    python -m src.predictor.api.batch_process \
        --input_dir tennis_videos/ \
        --output_dir annotated_videos/ \
        --model_path models/wasb_sbdt.pth \
        --model_type wasb_sbdt

    # ä¸¦åˆ—å‡¦ç† + çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
    python -m src.predictor.api.batch_process \
        --input_dir videos/ \
        --output_dir results/ \
        --model_path model.ckpt \
        --parallel_jobs 4 \
        --report_path batch_report.json \
        --config high_performance

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå‡¦ç†
    python -m src.predictor.api.batch_process \
        --input_list video_list.txt \
        --output_dir results/ \
        --model_path model.pth \
        --continue_on_error
"""

import argparse
import json
import logging
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

import torch

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.predictor import (
    VideoPipeline, 
    create_ball_detector,
    VisualizationConfig,
    HIGH_PERFORMANCE_CONFIG,
    MEMORY_EFFICIENT_CONFIG,
    REALTIME_CONFIG,
    DEBUG_CONFIG
)
from src.utils.logging_utils import setup_logging


def setup_arguments() -> argparse.ArgumentParser:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è¨­å®š"""
    parser = argparse.ArgumentParser(
        description="Tennis Ball Detection Batch Processing System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # === å…¥å‡ºåŠ›è¨­å®š ===
    io_group = parser.add_argument_group('Input/Output Settings')
    input_group = io_group.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        '--input_dir', type=str,
        help='å…¥åŠ›å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹'
    )
    input_group.add_argument(
        '--input_list', type=str,
        help='å…¥åŠ›å‹•ç”»ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (1è¡Œ1ãƒ•ã‚¡ã‚¤ãƒ«)'
    )
    
    io_group.add_argument(
        '--output_dir', type=str, required=True,
        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹'
    )
    io_group.add_argument(
        '--report_path', type=str,
        help='ãƒãƒƒãƒå‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‘ã‚¹ (JSONå½¢å¼)'
    )
    io_group.add_argument(
        '--file_patterns', type=str, nargs='+',
        default=['*.mp4', '*.avi', '*.mov'],
        help='å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³'
    )
    
    # === ãƒ¢ãƒ‡ãƒ«è¨­å®š ===
    model_group = parser.add_argument_group('Model Settings')
    model_group.add_argument(
        '--model_path', '-m', type=str, required=True,
        help='ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.ckpt ã¾ãŸã¯ .pth)'
    )
    model_group.add_argument(
        '--model_type', type=str, choices=['lite_tracknet', 'wasb_sbdt', 'auto'],
        default='auto',
        help='ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— (auto: æ‹¡å¼µå­ã‹ã‚‰è‡ªå‹•åˆ¤å®š)'
    )
    model_group.add_argument(
        '--config_path', type=str,
        help='ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    model_group.add_argument(
        '--device', type=str, choices=['auto', 'cpu', 'cuda'],
        default='auto',
        help='å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹ (auto: GPUè‡ªå‹•æ¤œå‡º)'
    )
    
    # === ãƒãƒƒãƒå‡¦ç†è¨­å®š ===
    batch_group = parser.add_argument_group('Batch Processing Settings')
    batch_group.add_argument(
        '--parallel_jobs', type=int, default=1,
        help='ä¸¦åˆ—å‡¦ç†ã‚¸ãƒ§ãƒ–æ•°'
    )
    batch_group.add_argument(
        '--config', type=str, 
        choices=['high_performance', 'memory_efficient', 'realtime', 'debug'],
        default='memory_efficient',
        help='ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆ'
    )
    batch_group.add_argument(
        '--continue_on_error', action='store_true',
        help='ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚ä»–ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’ç¶šè¡Œ'
    )
    batch_group.add_argument(
        '--overwrite', action='store_true',
        help='æ—¢å­˜å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã'
    )
    
    # === å¯è¦–åŒ–è¨­å®š ===
    vis_group = parser.add_argument_group('Visualization Settings')
    vis_group.add_argument(
        '--ball_radius', type=int, default=8,
        help='ãƒœãƒ¼ãƒ«æç”»åŠå¾„'
    )
    vis_group.add_argument(
        '--trajectory_length', type=int, default=20,
        help='è»Œè·¡è¡¨ç¤ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°'
    )
    vis_group.add_argument(
        '--enable_smoothing', action='store_true',
        help='ä½ç½®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœ‰åŠ¹åŒ–'
    )
    vis_group.add_argument(
        '--enable_prediction', action='store_true',
        help='ä½ç½®äºˆæ¸¬è¡¨ç¤ºæœ‰åŠ¹åŒ–'
    )
    vis_group.add_argument(
        '--confidence_threshold', type=float, default=0.5,
        help='ä¿¡é ¼åº¦é–¾å€¤'
    )
    
    # === ã‚·ã‚¹ãƒ†ãƒ è¨­å®š ===
    sys_group = parser.add_argument_group('System Settings')
    sys_group.add_argument(
        '--log_level', type=str, 
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«'
    )
    sys_group.add_argument(
        '--progress_interval', type=float, default=5.0,
        help='é€²æ—è¡¨ç¤ºé–“éš”ï¼ˆç§’ï¼‰'
    )
    
    return parser


def collect_video_files(args: argparse.Namespace) -> List[str]:
    """å‡¦ç†å¯¾è±¡å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«åé›†"""
    video_files = []
    
    if args.input_dir:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åé›†
        input_path = Path(args.input_dir)
        if not input_path.exists():
            raise FileNotFoundError(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_dir}")
        
        for pattern in args.file_patterns:
            video_files.extend(input_path.glob(pattern))
            
    elif args.input_list:
        # ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åé›†
        if not os.path.exists(args.input_list):
            raise FileNotFoundError(f"å…¥åŠ›ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_list}")
        
        with open(args.input_list, 'r', encoding='utf-8') as f:
            for line in f:
                video_path = line.strip()
                if video_path and os.path.exists(video_path):
                    video_files.append(Path(video_path))
    
    # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
    video_files = sorted([str(f) for f in video_files])
    
    logging.info(f"å‡¦ç†å¯¾è±¡å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {len(video_files)}ä»¶")
    return video_files


def get_output_path(video_path: str, output_dir: str) -> str:
    """å‡ºåŠ›ãƒ‘ã‚¹ç”Ÿæˆ"""
    video_name = Path(video_path).stem
    return os.path.join(output_dir, f"{video_name}_annotated.mp4")


def process_single_video(
    video_path: str,
    output_path: str,
    pipeline: VideoPipeline,
    detector_config: Dict[str, Any],
    vis_config: VisualizationConfig,
    overwrite: bool = False
) -> Dict[str, Any]:
    """å˜ä¸€å‹•ç”»å‡¦ç†"""
    result = {
        'video_path': video_path,
        'output_path': output_path,
        'status': 'pending',
        'start_time': time.time(),
        'processing_time': 0.0,
        'error_message': None,
        'stats': {}
    }
    
    try:
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if os.path.exists(output_path) and not overwrite:
            result['status'] = 'skipped'
            result['error_message'] = 'å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™'
            return result
        
        # å‡¦ç†å®Ÿè¡Œ
        logging.info(f"å‡¦ç†é–‹å§‹: {video_path}")
        processing_result = pipeline.process_video(
            video_path=video_path,
            detector_config=detector_config,
            output_path=output_path,
            vis_config=vis_config
        )
        
        result['processing_time'] = time.time() - result['start_time']
        result['status'] = 'completed'
        result['stats'] = processing_result
        
        logging.info(f"å‡¦ç†å®Œäº†: {video_path} ({result['processing_time']:.2f}ç§’)")
        
    except Exception as e:
        result['processing_time'] = time.time() - result['start_time']
        result['status'] = 'failed'
        result['error_message'] = str(e)
        
        logging.error(f"å‡¦ç†å¤±æ•—: {video_path} - {e}")
    
    return result


def get_pipeline_config(config_name: str) -> Dict[str, Any]:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šå–å¾—"""
    if config_name == 'high_performance':
        return HIGH_PERFORMANCE_CONFIG
    elif config_name == 'memory_efficient':
        return MEMORY_EFFICIENT_CONFIG
    elif config_name == 'realtime':
        return REALTIME_CONFIG
    elif config_name == 'debug':
        return DEBUG_CONFIG
    else:
        raise ValueError(f"Unknown config: {config_name}")


def get_detector_config(args: argparse.Namespace) -> Dict[str, Any]:
    """æ¤œå‡ºå™¨è¨­å®šå–å¾—"""
    # ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤å®š
    if args.model_type == 'auto':
        if args.model_path.endswith('.ckpt'):
            model_type = 'lite_tracknet'
        elif args.model_path.endswith('.pth'):
            model_type = 'wasb_sbdt'
        else:
            raise ValueError(f"Cannot auto-detect model type from: {args.model_path}")
    else:
        model_type = args.model_type
    
    config = {
        'model_path': args.model_path,
        'model_type': model_type,
        'device': device,
    }
    
    if args.config_path:
        config['config_path'] = args.config_path
        
    return config


def get_visualization_config(args: argparse.Namespace) -> VisualizationConfig:
    """å¯è¦–åŒ–è¨­å®šå–å¾—"""
    return VisualizationConfig(
        ball_radius=args.ball_radius,
        trajectory_length=args.trajectory_length,
        enable_smoothing=args.enable_smoothing,
        enable_prediction=args.enable_prediction,
        confidence_threshold=args.confidence_threshold
    )


def generate_batch_report(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ãƒãƒƒãƒå‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    total_files = len(results)
    completed_files = sum(1 for r in results if r['status'] == 'completed')
    failed_files = sum(1 for r in results if r['status'] == 'failed')
    skipped_files = sum(1 for r in results if r['status'] == 'skipped')
    
    total_processing_time = sum(r['processing_time'] for r in results)
    completed_results = [r for r in results if r['status'] == 'completed']
    
    # çµ±è¨ˆè¨ˆç®—
    total_frames = sum(r['stats'].get('total_frames', 0) for r in completed_results)
    total_detections = 0
    total_detection_frames = 0
    
    for r in completed_results:
        detections = r['stats'].get('detections', {})
        if detections:
            total_detections += sum(len(det_list) for det_list in detections.values())
            total_detection_frames += sum(1 for det_list in detections.values() if det_list)
    
    report = {
        'summary': {
            'total_files': total_files,
            'completed_files': completed_files,
            'failed_files': failed_files,
            'skipped_files': skipped_files,
            'success_rate': completed_files / total_files if total_files > 0 else 0.0,
            'total_processing_time': total_processing_time,
            'average_processing_time': total_processing_time / completed_files if completed_files > 0 else 0.0,
        },
        'detection_summary': {
            'total_frames': total_frames,
            'total_detections': total_detections,
            'frames_with_detection': total_detection_frames,
            'detection_rate': total_detection_frames / total_frames if total_frames > 0 else 0.0,
        },
        'detailed_results': results
    }
    
    return report


def save_batch_report(report: Dict[str, Any], output_path: str):
    """ãƒãƒƒãƒãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logging.info(f"ãƒãƒƒãƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    # å¼•æ•°è§£æ
    parser = setup_arguments()
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    setup_logging(level=args.log_level)
    logging.info("ğŸ¾ Tennis Ball Detection Batch Processing System é–‹å§‹")
    
    try:
        # å…¥åŠ›æ¤œè¨¼
        if not os.path.exists(args.model_path):
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.model_path}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(args.output_dir, exist_ok=True)
        
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«åé›†
        video_files = collect_video_files(args)
        if not video_files:
            raise ValueError("å‡¦ç†å¯¾è±¡ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # è¨­å®šå–å¾—
        pipeline_config = get_pipeline_config(args.config)
        detector_config = get_detector_config(args)
        vis_config = get_visualization_config(args)
        
        logging.info(f"ãƒ¢ãƒ‡ãƒ«: {detector_config['model_type']} ({args.model_path})")
        logging.info(f"ãƒ‡ãƒã‚¤ã‚¹: {detector_config['device']}")
        logging.info(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š: {args.config}")
        logging.info(f"ä¸¦åˆ—ã‚¸ãƒ§ãƒ–æ•°: {args.parallel_jobs}")
        
        # å‡¦ç†å®Ÿè¡Œ
        start_time = time.time()
        results = []
        
        if args.parallel_jobs == 1:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†
            pipeline = VideoPipeline(pipeline_config)
            
            for i, video_path in enumerate(video_files, 1):
                output_path = get_output_path(video_path, args.output_dir)
                logging.info(f"å‡¦ç†ä¸­ ({i}/{len(video_files)}): {video_path}")
                
                result = process_single_video(
                    video_path, output_path, pipeline,
                    detector_config, vis_config, args.overwrite
                )
                results.append(result)
                
                if result['status'] == 'failed' and not args.continue_on_error:
                    logging.error("ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                    break
                    
        else:
            # ä¸¦åˆ—å‡¦ç†
            logging.info(f"ä¸¦åˆ—å‡¦ç†é–‹å§‹ ({args.parallel_jobs}ä¸¦åˆ—)")
            
            def process_wrapper(video_path: str) -> Dict[str, Any]:
                pipeline = VideoPipeline(pipeline_config)
                output_path = get_output_path(video_path, args.output_dir)
                return process_single_video(
                    video_path, output_path, pipeline,
                    detector_config, vis_config, args.overwrite
                )
            
            with ThreadPoolExecutor(max_workers=args.parallel_jobs) as executor:
                # ã‚¿ã‚¹ã‚¯æŠ•å…¥
                future_to_video = {
                    executor.submit(process_wrapper, video_path): video_path
                    for video_path in video_files
                }
                
                # çµæœåé›†
                for future in as_completed(future_to_video):
                    result = future.result()
                    results.append(result)
                    
                    completed = len(results)
                    logging.info(f"é€²æ—: {completed}/{len(video_files)} ({completed/len(video_files)*100:.1f}%)")
                    
                    if result['status'] == 'failed' and not args.continue_on_error:
                        logging.error("ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                        # æ®‹ã‚Šã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                        for remaining_future in future_to_video:
                            remaining_future.cancel()
                        break
        
        total_time = time.time() - start_time
        
        # çµæœé›†è¨ˆ
        completed = sum(1 for r in results if r['status'] == 'completed')
        failed = sum(1 for r in results if r['status'] == 'failed')
        skipped = sum(1 for r in results if r['status'] == 'skipped')
        
        # çµæœè¡¨ç¤º
        logging.info("ğŸ¯ ãƒãƒƒãƒå‡¦ç†å®Œäº†!")
        logging.info(f"ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        logging.info(f"å‡¦ç†çµæœ: å®Œäº†={completed}, å¤±æ•—={failed}, ã‚¹ã‚­ãƒƒãƒ—={skipped}")
        logging.info(f"æˆåŠŸç‡: {completed/len(results)*100:.1f}%")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        if args.report_path:
            report = generate_batch_report(results)
            save_batch_report(report, args.report_path)
        
        # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
        failed_files = [r for r in results if r['status'] == 'failed']
        if failed_files:
            logging.warning(f"å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ« ({len(failed_files)}ä»¶):")
            for result in failed_files:
                logging.warning(f"  {result['video_path']}: {result['error_message']}")
        
    except Exception as e:
        logging.error(f"ãƒãƒƒãƒå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main() 