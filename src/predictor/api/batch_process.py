#!/usr/bin/env python3
"""
Tennis Ball Detection Batch Processing API
==========================================

ğŸ¾ ãƒ†ãƒ‹ã‚¹ãƒœãƒ¼ãƒ«æ¤œå‡ºãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 

è¤‡æ•°ã®ãƒ†ãƒ‹ã‚¹å‹•ç”»ã‚’åŠ¹ç‡çš„ã«ä¸€æ‹¬å‡¦ç†ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚
ä¸¦åˆ—å‡¦ç†ã€é€²æ—ç®¡ç†ã€ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

Features:
- ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å‡¦ç†
- ğŸ”„ ä¸¦åˆ—ãƒãƒƒãƒå‡¦ç†
- ğŸ“Š çµ±ä¸€çµ±è¨ˆæƒ…å ±
- ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ»ç¶šè¡Œ
- ğŸ“ˆ è©³ç´°é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ

Usage:
    python -m src.predictor.api.batch_process \
        --config-path ../../configs/infer \
        --config-name batch_process \
        io.input_dir=videos/ \
        io.output_dir=results/ \
        model.model_path=checkpoints/model.ckpt \
        batch.parallel_jobs=4

Examples:
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å‡¦ç†
    python -m src.predictor.api.batch_process \
        --config-path ../../configs/infer \
        --config-name batch_process \
        io.input_dir=tennis_videos/ \
        io.output_dir=annotated_videos/ \
        model.model_path=models/wasb_sbdt.pth \
        model=wasb_sbdt

    # ä¸¦åˆ—å‡¦ç† + çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
    python -m src.predictor.api.batch_process \
        --config-path ../../configs/infer \
        --config-name batch_process \
        io.input_dir=videos/ \
        io.output_dir=results/ \
        model.model_path=model.ckpt \
        batch.parallel_jobs=4 \
        io.report_path=batch_report.json \
        pipeline=high_performance

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå‡¦ç†
    python -m src.predictor.api.batch_process \
        --config-path ../../configs/infer \
        --config-name batch_process \
        io.input_list=video_list.txt \
        io.output_dir=results/ \
        model.model_path=model.pth \
        batch.continue_on_error=true
"""

import json
import logging
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

import hydra
import torch
from omegaconf import DictConfig, OmegaConf

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.predictor import (
    VideoPipeline, 
    create_ball_detector,
    VisualizationConfig,
    HIGH_PERFORMANCE_CONFIG,
    MEMORY_EFFICIENT_CONFIG,
    REALTIME_CONFIG,
    DEBUG_CONFIG
)


def collect_video_files(cfg: DictConfig) -> List[str]:
    """å‡¦ç†å¯¾è±¡å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«åé›†"""
    video_files = []
    
    if cfg.io.input_dir:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åé›†
        input_path = Path(cfg.io.input_dir)
        if not input_path.exists():
            raise FileNotFoundError(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {cfg.io.input_dir}")
        
        for pattern in cfg.io.file_patterns:
            video_files.extend(input_path.glob(pattern))
            
    elif cfg.io.input_list:
        # ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åé›†
        if not os.path.exists(cfg.io.input_list):
            raise FileNotFoundError(f"å…¥åŠ›ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {cfg.io.input_list}")
        
        with open(cfg.io.input_list, 'r', encoding='utf-8') as f:
            for line in f:
                video_path = line.strip()
                if video_path and os.path.exists(video_path):
                    video_files.append(Path(video_path))
    
    # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
    video_files = sorted([str(f) for f in video_files])
    
    logging.info(f"å‡¦ç†å¯¾è±¡å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {len(video_files)}ä»¶")
    return video_files


def get_output_path(video_path: str, output_dir: str) -> str:
    """å‡ºåŠ›ãƒ‘ã‚¹ç”Ÿæˆ"""
    video_name = Path(video_path).stem
    return os.path.join(output_dir, f"{video_name}_annotated.mp4")


def process_single_video(
    video_path: str,
    output_path: str,
    pipeline: VideoPipeline,
    detector_config: Dict[str, Any],
    vis_config: VisualizationConfig,
    overwrite: bool = False
) -> Dict[str, Any]:
    """å˜ä¸€å‹•ç”»å‡¦ç†"""
    result = {
        'video_path': video_path,
        'output_path': output_path,
        'status': 'pending',
        'start_time': time.time(),
        'processing_time': 0.0,
        'error_message': None,
        'stats': {}
    }
    
    try:
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if os.path.exists(output_path) and not overwrite:
            result['status'] = 'skipped'
            result['error_message'] = 'å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™'
            return result
        
        # å‡¦ç†å®Ÿè¡Œ
        logging.info(f"å‡¦ç†é–‹å§‹: {video_path}")
        processing_result = pipeline.process_video(
            video_path=video_path,
            detector_config=detector_config,
            output_path=output_path,
            vis_config=vis_config
        )
        
        result['processing_time'] = time.time() - result['start_time']
        result['status'] = 'completed'
        result['stats'] = processing_result
        
        logging.info(f"å‡¦ç†å®Œäº†: {video_path} ({result['processing_time']:.2f}ç§’)")
        
    except Exception as e:
        result['processing_time'] = time.time() - result['start_time']
        result['status'] = 'failed'
        result['error_message'] = str(e)
        
        logging.error(f"å‡¦ç†å¤±æ•—: {video_path} - {e}")
    
    return result


def get_pipeline_config(cfg: DictConfig) -> Dict[str, Any]:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šå–å¾—"""
    if cfg.pipeline.type == 'high_performance':
        base_config = HIGH_PERFORMANCE_CONFIG
    elif cfg.pipeline.type == 'memory_efficient':
        base_config = MEMORY_EFFICIENT_CONFIG
    elif cfg.pipeline.type == 'realtime':
        base_config = REALTIME_CONFIG
    elif cfg.pipeline.type == 'debug':
        base_config = DEBUG_CONFIG
    else:
        raise ValueError(f"Unknown pipeline type: {cfg.pipeline.type}")
    
    # ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºé©ç”¨
    config = base_config.copy()
    config.update({
        'batch_size': cfg.pipeline.batch_size,
        'num_workers': cfg.pipeline.num_workers,
        'queue_size': cfg.pipeline.queue_size,
    })
        
    return config


def get_detector_config(cfg: DictConfig) -> Dict[str, Any]:
    """æ¤œå‡ºå™¨è¨­å®šå–å¾—"""
    # ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º
    if cfg.model.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = cfg.model.device
    
    # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤å®š
    if cfg.model.type == 'auto':
        if cfg.model.model_path.endswith('.ckpt'):
            model_type = 'lite_tracknet'
        elif cfg.model.model_path.endswith('.pth'):
            model_type = 'wasb_sbdt'
        else:
            raise ValueError(f"Cannot auto-detect model type from: {cfg.model.model_path}")
    else:
        model_type = cfg.model.type
    
    config = {
        'model_path': cfg.model.model_path,
        'model_type': model_type,
        'device': device,
    }
    
    if cfg.model.config_path:
        config['config_path'] = cfg.model.config_path
        
    return config


def get_visualization_config(cfg: DictConfig) -> VisualizationConfig:
    """å¯è¦–åŒ–è¨­å®šå–å¾—"""
    return VisualizationConfig(
        ball_radius=cfg.visualization.ball_radius,
        trajectory_length=cfg.visualization.trajectory_length,
        enable_smoothing=cfg.visualization.enable_smoothing,
        enable_prediction=cfg.visualization.enable_prediction,
        confidence_threshold=cfg.visualization.confidence_threshold
    )


def generate_batch_report(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ãƒãƒƒãƒå‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    total_files = len(results)
    completed_files = sum(1 for r in results if r['status'] == 'completed')
    failed_files = sum(1 for r in results if r['status'] == 'failed')
    skipped_files = sum(1 for r in results if r['status'] == 'skipped')
    
    total_processing_time = sum(r['processing_time'] for r in results)
    completed_results = [r for r in results if r['status'] == 'completed']
    
    # çµ±è¨ˆè¨ˆç®—
    total_frames = sum(r['stats'].get('total_frames', 0) for r in completed_results)
    total_detections = 0
    total_detection_frames = 0
    
    for r in completed_results:
        detections = r['stats'].get('detections', {})
        if detections:
            total_detections += sum(len(det_list) for det_list in detections.values())
            total_detection_frames += sum(1 for det_list in detections.values() if det_list)
    
    report = {
        'summary': {
            'total_files': total_files,
            'completed_files': completed_files,
            'failed_files': failed_files,
            'skipped_files': skipped_files,
            'success_rate': completed_files / total_files if total_files > 0 else 0.0,
            'total_processing_time': total_processing_time,
            'average_processing_time': total_processing_time / completed_files if completed_files > 0 else 0.0,
        },
        'detection_summary': {
            'total_frames': total_frames,
            'total_detections': total_detections,
            'frames_with_detection': total_detection_frames,
            'detection_rate': total_detection_frames / total_frames if total_frames > 0 else 0.0,
        },
        'detailed_results': results
    }
    
    return report


def save_batch_report(report: Dict[str, Any], output_path: str):
    """ãƒãƒƒãƒãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logging.info(f"ãƒãƒƒãƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {output_path}")


@hydra.main(version_base=None, config_path="../../configs/infer", config_name="batch_process")
def validate_batch_config(cfg: DictConfig) -> None:
    """ãƒãƒƒãƒå‡¦ç†è¨­å®šæ¤œè¨¼"""
    # å…¥åŠ›ã‚½ãƒ¼ã‚¹æ¤œè¨¼
    if not cfg.io.input_dir and not cfg.io.input_list:
        raise ValueError("Either input_dir or input_list must be specified")
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼
    required_fields = [
        ('io.output_dir', 'output directory'),
        ('model.model_path', 'model file path')
    ]
    
    for field_path, description in required_fields:
        field_value = cfg
        for key in field_path.split('.'):
            field_value = getattr(field_value, key, None)
        if not field_value:
            raise ValueError(f"{field_path} ({description}) is required but not provided")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not os.path.exists(cfg.model.model_path):
        raise FileNotFoundError(f"Model file not found: {cfg.model.model_path}")
    
    if cfg.io.input_list and not os.path.exists(cfg.io.input_list):
        raise FileNotFoundError(f"Input list file not found: {cfg.io.input_list}")
    
    if cfg.io.input_dir and not os.path.exists(cfg.io.input_dir):
        raise FileNotFoundError(f"Input directory not found: {cfg.io.input_dir}")


def main(cfg: DictConfig) -> None:
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=getattr(logging, cfg.system.log_level),
        format='[%(levelname)s] %(message)s'
    )
    logging.info("ğŸ¾ Tennis Ball Detection Batch Processing System é–‹å§‹")
    
    try:
        # è¨­å®šæ¤œè¨¼
        validate_batch_config(cfg)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(cfg.io.output_dir, exist_ok=True)
        
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«åé›†
        video_files = collect_video_files(cfg)
        if not video_files:
            raise ValueError("å‡¦ç†å¯¾è±¡ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # è¨­å®šå–å¾—
        pipeline_config = get_pipeline_config(cfg)
        detector_config = get_detector_config(cfg)
        vis_config = get_visualization_config(cfg)
        
        logging.info(f"è¨­å®š: {OmegaConf.to_yaml(cfg)}")
        logging.info(f"ãƒ¢ãƒ‡ãƒ«: {detector_config['model_type']} ({cfg.model.model_path})")
        logging.info(f"ãƒ‡ãƒã‚¤ã‚¹: {detector_config['device']}")
        logging.info(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š: {cfg.pipeline.type}")
        logging.info(f"ä¸¦åˆ—ã‚¸ãƒ§ãƒ–æ•°: {cfg.batch.parallel_jobs}")
        
        # å‡¦ç†å®Ÿè¡Œ
        start_time = time.time()
        results = []
        
        if cfg.batch.parallel_jobs == 1:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†
            pipeline = VideoPipeline(pipeline_config)
            
            for i, video_path in enumerate(video_files, 1):
                output_path = get_output_path(video_path, cfg.io.output_dir)
                logging.info(f"å‡¦ç†ä¸­ ({i}/{len(video_files)}): {video_path}")
                
                result = process_single_video(
                    video_path, output_path, pipeline,
                    detector_config, vis_config, cfg.batch.overwrite
                )
                results.append(result)
                
                if result['status'] == 'failed' and not cfg.batch.continue_on_error:
                    logging.error("ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                    break
                    
        else:
            # ä¸¦åˆ—å‡¦ç†
            logging.info(f"ä¸¦åˆ—å‡¦ç†é–‹å§‹ ({cfg.batch.parallel_jobs}ä¸¦åˆ—)")
            
            def process_wrapper(video_path: str) -> Dict[str, Any]:
                pipeline = VideoPipeline(pipeline_config)
                output_path = get_output_path(video_path, cfg.io.output_dir)
                return process_single_video(
                    video_path, output_path, pipeline,
                    detector_config, vis_config, cfg.batch.overwrite
                )
            
            with ThreadPoolExecutor(max_workers=cfg.batch.parallel_jobs) as executor:
                # ã‚¿ã‚¹ã‚¯æŠ•å…¥
                future_to_video = {
                    executor.submit(process_wrapper, video_path): video_path
                    for video_path in video_files
                }
                
                # çµæœåé›†
                for future in as_completed(future_to_video):
                    result = future.result()
                    results.append(result)
                    
                    completed = len(results)
                    logging.info(f"é€²æ—: {completed}/{len(video_files)} ({completed/len(video_files)*100:.1f}%)")
                    
                    if result['status'] == 'failed' and not cfg.batch.continue_on_error:
                        logging.error("ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                        # æ®‹ã‚Šã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                        for remaining_future in future_to_video:
                            remaining_future.cancel()
                        break
        
        total_time = time.time() - start_time
        
        # çµæœé›†è¨ˆ
        completed = sum(1 for r in results if r['status'] == 'completed')
        failed = sum(1 for r in results if r['status'] == 'failed')
        skipped = sum(1 for r in results if r['status'] == 'skipped')
        
        # çµæœè¡¨ç¤º
        logging.info("ğŸ¯ ãƒãƒƒãƒå‡¦ç†å®Œäº†!")
        logging.info(f"ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        logging.info(f"å‡¦ç†çµæœ: å®Œäº†={completed}, å¤±æ•—={failed}, ã‚¹ã‚­ãƒƒãƒ—={skipped}")
        logging.info(f"æˆåŠŸç‡: {completed/len(results)*100:.1f}%")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        if cfg.io.report_path:
            report = generate_batch_report(results)
            save_batch_report(report, cfg.io.report_path)
        
        # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
        failed_files = [r for r in results if r['status'] == 'failed']
        if failed_files:
            logging.warning(f"å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ« ({len(failed_files)}ä»¶):")
            for result in failed_files:
                logging.warning(f"  {result['video_path']}: {result['error_message']}")
        
    except Exception as e:
        logging.error(f"ãƒãƒƒãƒå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main() 