"""
Visualization Module
====================

ğŸ¨ ãƒ†ãƒ‹ã‚¹ãƒœãƒ¼ãƒ«æ¤œå‡ºçµæœå¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ 

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ãƒœãƒ¼ãƒ«æ¤œå‡ºçµæœã‚’é«˜å“è³ªãªå‹•ç”»ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã¨ã—ã¦å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã®
åŒ…æ‹¬çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚è»Œè·¡è¿½è·¡ã€ä¿¡é ¼åº¦è¡¨ç¤ºã€äºˆæ¸¬å¯è¦–åŒ–ãªã©ã€
åˆ†æã¨è©•ä¾¡ã«å¿…è¦ãªå…¨ã¦ã®è¦–è¦šåŒ–æ©Ÿèƒ½ã‚’çµ±åˆã—ã¦ã„ã¾ã™ã€‚

ä¸»ãªç‰¹å¾´:
- ğŸ¥ é«˜å“è³ªãªã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤å‹•ç”»ç”Ÿæˆ
- ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æç”»ã¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
- ğŸ“Š ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªè¦–è¦šåŒ–è¨­å®š
- âš¡ åŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†ã¨ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†

========================================
ğŸš€ Quick Start
========================================

```python
from src.predictor.visualization import VideoOverlay, VisualizationConfig

# 1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ç°¡å˜é–‹å§‹
overlay = VideoOverlay()
output_path = overlay.create_overlay_video(
    video_path="input.mp4",
    detections=detection_results,
    output_path="output_with_overlay.mp4"
)

# 2. ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã«ã‚ˆã‚‹é«˜åº¦ãªåˆ¶å¾¡
config = VisualizationConfig(
    ball_radius=12,
    show_trajectory=True,
    trajectory_length=20,
    enable_smoothing=True
)
overlay = VideoOverlay(config)
```

========================================
ğŸ—ï¸ Core Components
========================================

VideoOverlay - å‹•ç”»ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚¨ãƒ³ã‚¸ãƒ³
-------------------------------------
å‹•ç”»å…¨ä½“ã«å¯¾ã™ã‚‹ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤å‡¦ç†ã¨ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã‚’æ‹…å½“

**ä¸»è¦æ©Ÿèƒ½:**
- å®Œå…¨ãªå‹•ç”»ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆ
- é€²æ—ç®¡ç†ã¨ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ã‚µãƒãƒªãƒ¼å‹•ç”»ä½œæˆï¼ˆæ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰
- ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã¨çµ±è¨ˆæƒ…å ±ç”Ÿæˆ

```python
from src.predictor.visualization import VideoOverlay

overlay = VideoOverlay()

# å®Œå…¨ãªã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤å‹•ç”»ä½œæˆ
output_path = overlay.create_overlay_video(
    video_path="tennis_match.mp4",
    detections=ball_detections,
    output_path="annotated_match.mp4",
    progress_callback=lambda p: print(f"Progress: {p*100:.1f}%")
)

# æ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã®ã‚µãƒãƒªãƒ¼å‹•ç”»
summary_path = overlay.create_detection_summary_video(
    video_path="tennis_match.mp4",
    detections=ball_detections,
    output_path="best_detections.mp4",
    summary_frames=50
)

# çµ±è¨ˆæƒ…å ±å–å¾—
stats = overlay.get_processing_stats(ball_detections)
print(f"Total detections: {stats['total_detections']}")
print(f"Frames with balls: {stats['frames_with_detections']}")
```

DetectionRenderer - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æç”»ã‚¨ãƒ³ã‚¸ãƒ³
-----------------------------------------
å€‹åˆ¥ãƒ•ãƒ¬ãƒ¼ãƒ ã¸ã®æ¤œå‡ºçµæœæç”»ã¨è¦–è¦šåŠ¹æœã‚’æ‹…å½“

**ä¸»è¦æ©Ÿèƒ½:**
- é«˜ç²¾åº¦ãªçƒä½“ä½ç½®æç”»
- å‹•çš„è»Œè·¡å¯è¦–åŒ–ï¼ˆåšã¿å¤‰åŒ–ï¼‰
- ä½ç½®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã¨ãƒã‚¤ã‚ºé™¤å»
- æœªæ¥äºˆæ¸¬ä½ç½®ã®è¡¨ç¤º

```python
from src.predictor.visualization import DetectionRenderer, VisualizationConfig

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§ãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼ä½œæˆ
config = VisualizationConfig(
    ball_color=(0, 255, 0),      # ç·‘è‰²ã®çƒä½“
    trajectory_length=15,         # 15ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®è»Œè·¡
    enable_smoothing=True,        # ä½ç½®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœ‰åŠ¹
    enable_prediction=True        # äºˆæ¸¬è¡¨ç¤ºæœ‰åŠ¹
)
renderer = DetectionRenderer(config)

# ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§ã®æç”»
for frame_idx, frame in enumerate(video_frames):
    frame_detections = detections.get(f"frame_{frame_idx}", [])
    
    rendered_frame = renderer.render_frame(
        frame=frame,
        detections=frame_detections,
        frame_info={
            'frame_number': frame_idx,
            'timestamp': frame_idx / fps,
            'detection_count': len(frame_detections)
        }
    )
    
    cv2.imshow('Ball Detection', rendered_frame)
```

VisualizationConfig - è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
------------------------------------
å…¨ã¦ã®è¦–è¦šåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ±ä¸€ç®¡ç†

**è¨­å®šã‚«ãƒ†ã‚´ãƒª:**
- **çƒä½“æç”»**: è‰²ã€ã‚µã‚¤ã‚ºã€ä¸­å¿ƒç‚¹è¡¨ç¤º
- **è»Œè·¡è¡¨ç¤º**: é•·ã•ã€è‰²ã€åšã¿å¤‰åŒ–
- **ãƒ†ã‚­ã‚¹ãƒˆ**: ãƒ•ã‚©ãƒ³ãƒˆã€è‰²ã€ä½ç½®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
- **å‹•ç”»å‡ºåŠ›**: ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã€å“è³ªã€ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹
- **é«˜åº¦æ©Ÿèƒ½**: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã€äºˆæ¸¬ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```python
from src.predictor.visualization import VisualizationConfig
from src.predictor.visualization.config import (
    HIGH_QUALITY_CONFIG,
    MINIMAL_CONFIG,
    TRAJECTORY_FOCUSED_CONFIG
)

# ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®šã®ä½¿ç”¨
config = HIGH_QUALITY_CONFIG  # é«˜å“è³ªæç”»è¨­å®š

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šä½œæˆ
custom_config = VisualizationConfig(
    # çƒä½“æç”»è¨­å®š
    ball_radius=10,
    ball_color=(255, 0, 0),     # é’è‰² (BGR)
    center_radius=4,
    center_color=(255, 255, 255),
    
    # è»Œè·¡è¨­å®š
    show_trajectory=True,
    trajectory_length=25,
    trajectory_color=(0, 255, 255),  # é»„è‰²
    trajectory_max_thickness=5,
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    confidence_threshold=0.4,
    
    # é«˜åº¦æ©Ÿèƒ½
    enable_smoothing=True,
    smoothing_window=5,
    enable_prediction=True,
    prediction_frames=3
)

# è¨­å®šã®å‹•çš„æ›´æ–°
config.update(
    ball_radius=15,
    trajectory_length=30
)
```

========================================
ğŸ”§ Advanced Usage Patterns
========================================

å®Ÿæ™‚é–“å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
--------------------
```python
import cv2
from src.predictor.visualization import DetectionRenderer, VisualizationConfig

def real_time_visualization(detector, video_source=0):
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ç”¨è¨­å®š
    config = VisualizationConfig(
        ball_radius=8,
        show_trajectory=True,
        trajectory_length=10,
        enable_smoothing=True,
        smoothing_window=3
    )
    
    renderer = DetectionRenderer(config)
    cap = cv2.VideoCapture(video_source)
    
    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            # æ¤œå‡ºå®Ÿè¡Œ
            detections = detector.detect_frame(frame)
            
            # å¯è¦–åŒ–
            rendered_frame = renderer.render_frame(frame, detections)
            
            cv2.imshow('Real-time Ball Detection', rendered_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    finally:
        cap.release()
        cv2.destroyAllWindows()
```

ãƒãƒƒãƒå‡¦ç†ã¨ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†
------------------------
```python
from src.predictor.visualization import VideoOverlay
import time

def batch_process_videos(video_list, detection_results):
    overlay = VideoOverlay()
    
    def progress_callback(progress):
        bar_length = 50
        filled_length = int(bar_length * progress)
        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
        print(f'\rProgress: |{bar}| {progress*100:.1f}%', end='', flush=True)
    
    for video_path, detections in zip(video_list, detection_results):
        output_path = video_path.replace('.mp4', '_annotated.mp4')
        
        print(f"\nProcessing: {video_path}")
        overlay.create_overlay_video(
            video_path=video_path,
            detections=detections,
            output_path=output_path,
            progress_callback=progress_callback
        )
        print(f"\nCompleted: {output_path}")
```

ã‚«ã‚¹ã‚¿ãƒ æç”»ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
--------------------
```python
from src.predictor.visualization import DetectionRenderer
import cv2

class CustomRenderer(DetectionRenderer):
    def render_frame(self, frame, detections, frame_info=None):
        # åŸºæœ¬æç”»ã‚’å®Ÿè¡Œ
        rendered_frame = super().render_frame(frame, detections, frame_info)
        
        # ã‚«ã‚¹ã‚¿ãƒ è¦ç´ è¿½åŠ 
        if detections:
            # æ¤œå‡ºæ•°ã«å¿œã˜ãŸèƒŒæ™¯è‰²å¤‰æ›´
            detection_count = len(detections)
            if detection_count > 3:
                # å¤šæ•°æ¤œå‡ºæ™‚ã¯èƒŒæ™¯ã‚’è–„ç·‘ã«
                overlay = rendered_frame.copy()
                overlay[:] = (0, 255, 0)
                rendered_frame = cv2.addWeighted(rendered_frame, 0.9, overlay, 0.1, 0)
            
            # ã‚«ã‚¹ã‚¿ãƒ ä¿¡é ¼åº¦ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            self._draw_confidence_histogram(rendered_frame, detections)
        
        return rendered_frame
    
    def _draw_confidence_histogram(self, frame, detections):
        # ä¿¡é ¼åº¦åˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æç”»
        confidences = [det[2] for det in detections if len(det) >= 3]
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å®Ÿè£…...
```

========================================
ğŸ“Š Data Format Specifications
========================================

Detection Data Structure
-------------------------
```python
# å…¥åŠ›æ¤œå‡ºãƒ‡ãƒ¼ã‚¿å½¢å¼
detections: Dict[str, List[List[float]]] = {
    "frame_000000": [
        [x_norm, y_norm, confidence],  # æ­£è¦åŒ–åº§æ¨™ [0, 1]
        [0.45, 0.32, 0.89],           # ä¾‹: x=45%, y=32%, conf=89%
        ...
    ],
    "frame_000001": [...],
    ...
}

# ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±ãƒ‡ãƒ¼ã‚¿
frame_info: Dict[str, Any] = {
    'frame_number': int,      # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·
    'timestamp': float,       # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆç§’ï¼‰
    'detection_count': int,   # æ¤œå‡ºæ•°
    'fps': float,            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    'resolution': tuple      # (width, height)ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
}
```

Configuration Schema
--------------------
```python
# åŸºæœ¬æç”»è¨­å®š
ball_radius: int = 8                    # çƒä½“åŠå¾„
center_radius: int = 3                  # ä¸­å¿ƒç‚¹åŠå¾„
ball_color: Tuple[int, int, int]        # BGRè‰²æŒ‡å®š
center_color: Tuple[int, int, int]      # ä¸­å¿ƒç‚¹è‰²

# è»Œè·¡è¨­å®š
show_trajectory: bool = True            # è»Œè·¡è¡¨ç¤ºæœ‰åŠ¹/ç„¡åŠ¹
trajectory_length: int = 15             # è»Œè·¡ç‚¹æ•°
trajectory_color: Tuple[int, int, int]  # è»Œè·¡è‰²
trajectory_max_thickness: int = 3       # æœ€å¤§ç·šå¹…
trajectory_min_thickness: int = 1       # æœ€å°ç·šå¹…

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
confidence_threshold: float = 0.3       # ä¿¡é ¼åº¦é–¾å€¤

# é«˜åº¦æ©Ÿèƒ½
enable_smoothing: bool = False          # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœ‰åŠ¹
smoothing_window: int = 3               # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
enable_prediction: bool = False         # äºˆæ¸¬è¡¨ç¤ºæœ‰åŠ¹
prediction_frames: int = 2              # äºˆæ¸¬ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
```

========================================
âš¡ Performance Optimization
========================================

ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
-----------
```python
# å¤§ããªãƒ“ãƒ‡ã‚ªå‡¦ç†æ™‚ã®ãƒ¡ãƒ¢ãƒªç®¡ç†
import gc

def memory_efficient_processing(video_path, detections):
    overlay = VideoOverlay()
    
    # ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§ã®å‡¦ç†
    chunk_size = 1000  # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    total_frames = get_video_frame_count(video_path)
    
    for start_frame in range(0, total_frames, chunk_size):
        end_frame = min(start_frame + chunk_size, total_frames)
        
        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®æ¤œå‡ºãƒ‡ãƒ¼ã‚¿
        chunk_detections = {
            k: v for k, v in detections.items()
            if start_frame <= int(k.replace('frame_', '')) < end_frame
        }
        
        # å‡¦ç†å®Ÿè¡Œ
        process_chunk(video_path, chunk_detections, start_frame, end_frame)
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del chunk_detections
        gc.collect()
```

ä¸¦åˆ—å‡¦ç†å¯¾å¿œ
-----------
```python
from concurrent.futures import ThreadPoolExecutor
import numpy as np

def parallel_frame_rendering(frames, detections, config):
    renderer = DetectionRenderer(config)
    
    def render_single_frame(args):
        frame_idx, frame = args
        frame_detections = detections.get(f"frame_{frame_idx:06d}", [])
        return renderer.render_frame(frame, frame_detections)
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        rendered_frames = list(executor.map(
            render_single_frame,
            enumerate(frames)
        ))
    
    return rendered_frames
```

========================================
â„¹ï¸ Package Information
========================================

Core Classes:
- VideoOverlay: å‹•ç”»ãƒ¬ãƒ™ãƒ«ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤å‡¦ç†ã¨ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
- DetectionRenderer: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã®æç”»ã‚¨ãƒ³ã‚¸ãƒ³ã¨è¦–è¦šåŠ¹æœ
- VisualizationConfig: çµ±ä¸€è¨­å®šç®¡ç†ã¨ãƒ—ãƒªã‚»ãƒƒãƒˆæä¾›

Advanced Features:
- Real-time visualization: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æç”»å¯¾å¿œ
- Trajectory tracking: å‹•çš„è»Œè·¡è¿½è·¡ã¨è¡¨ç¤º
- Predictive visualization: æœªæ¥ä½ç½®äºˆæ¸¬è¡¨ç¤º
- Custom rendering: æ‹¡å¼µå¯èƒ½ãªæç”»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

Performance: é«˜åŠ¹ç‡ãƒ¡ãƒ¢ãƒªç®¡ç†ã€ä¸¦åˆ—å‡¦ç†å¯¾å¿œã€å¤§å®¹é‡å‹•ç”»å¯¾å¿œ
Output Quality: é«˜å“è³ªã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªè§£åƒåº¦ã¨FPS
Compatibility: OpenCVçµ±åˆã€NumPyæœ€é©åŒ–ã€ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ
"""

from .overlay import VideoOverlay
from .renderer import DetectionRenderer
from .config import VisualizationConfig

__all__ = [
    'VideoOverlay',
    'DetectionRenderer',
    'VisualizationConfig',
]