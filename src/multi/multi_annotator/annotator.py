# multi_flow_annotator/annotator.py

import queue
import time
from pathlib import Path
from typing import List, Union, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor

import threading
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import cv2

from .definitions import PreprocessTask
from .coco_utils import CocoManager
from .file_utils import validate_paths, collect_and_group_images, load_frame, extract_ids_from_path
from .workers.ball_worker import BallWorker
from .workers.court_worker import CourtWorker
from .workers.pose_worker import PoseWorker

class MultiFlowAnnotator:
    """ãƒãƒ«ãƒãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ç”»åƒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹ç‡çš„ã«è¡Œã†ã‚¯ãƒ©ã‚¹ã€‚

    å‰å‡¦ç†ã€æ¨è«–ã€å¾Œå‡¦ç†ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¸¦åˆ—åŒ–ã—ã€GPUä½¿ç”¨ç‡ã®æœ€å¤§åŒ–ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
    ãƒ¡ã‚¤ãƒ³ã®è²¬å‹™ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®ç®¡ç†ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆ¶å¾¡ã€ã‚¿ã‚¹ã‚¯ã®æŠ•å…¥ã§ã™ã€‚
    """

    def __init__(
        self,
        ball_predictor, court_predictor, pose_predictor,
        batch_sizes: dict = None,
        vis_thresholds: dict = None,
        preprocess_workers: int = 4,
        max_queue_size: int = 8,
        debug: bool = False,
    ):
        """MultiFlowAnnotatorã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            ball_predictor: ãƒœãƒ¼ãƒ«æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å™¨ã€‚
            court_predictor: ã‚³ãƒ¼ãƒˆæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å™¨ã€‚
            pose_predictor: ãƒãƒ¼ã‚ºæ¨å®šãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å™¨ã€‚
            batch_sizes (dict): å„ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®šã€‚
            vis_thresholds (dict): å„ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯è¦–æ€§é–¾å€¤ã€‚
            preprocess_workers (int): ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿ãªã©å‰å‡¦ç†ç”¨ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã€‚
            max_queue_size (int): å„å‡¦ç†ã‚­ãƒ¥ãƒ¼ã®æœ€å¤§ã‚µã‚¤ã‚ºã€‚
            debug (bool): ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã€‚
        """
        self.batch_sizes = batch_sizes or {"ball": 8, "court": 8, "pose": 8}
        self.vis_thresholds = vis_thresholds or {"ball": 0.5, "court": 0.6, "pose": 0.5}
        self.max_queue_size = max_queue_size
        self.debug = debug
        
        self.coco_manager = CocoManager()
        self.image_id_map: Dict[Path, int] = {}
        self.grouped_entries: Dict[Tuple[int, int], List[Tuple[int, Path]]] = {}

        # å‡¦ç†ã‚­ãƒ¥ãƒ¼ã®åˆæœŸåŒ–
        self._initialize_queues()

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆæœŸåŒ–
        self.workers = {
            "ball": BallWorker(
                ball_predictor, self.queues["ball"]["preprocess"], self.queues["ball"]["inference"],
                self.queues["ball"]["postprocess"], self.coco_manager, self.vis_thresholds["ball"], self.debug
            ),
            "court": CourtWorker(
                court_predictor, self.queues["court"]["preprocess"], self.queues["court"]["inference"],
                self.queues["court"]["postprocess"], self.coco_manager, self.vis_thresholds["court"], self.debug
            ),
            "pose": PoseWorker(
                pose_predictor, self.queues["pose"]["preprocess"], self.queues["pose"]["inference"],
                self.queues["pose"]["postprocess"], self.coco_manager, self.vis_thresholds["pose"], self.debug
            ),
        }

    def _initialize_queues(self):
        """å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ã®ã‚­ãƒ¥ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        self.queues = {}
        for name in ["ball", "court", "pose"]:
            self.queues[name] = {
                "preprocess": queue.Queue(maxsize=self.max_queue_size),
                "inference": queue.Queue(maxsize=self.max_queue_size),
                "postprocess": queue.Queue(maxsize=self.max_queue_size),
            }

    def _start_workers(self):
        """å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚"""
        for worker in self.workers.values():
            worker.start()
        print("âœ… å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")

    def _stop_workers(self):
        """å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã™ã€‚"""
        print("\nâ³ ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®åœæ­¢å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        for worker in self.workers.values():
            worker.stop()
        print("âœ… å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")

    def _prepare_image_metadata(
    self, input_dir: Path, grouped_files: Dict[Tuple[int, int], List[Path]]
) -> int:
        """ã€é«˜é€ŸåŒ–ç‰ˆã€‘ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—å‡¦ç†ã§æº–å‚™ã—ã€COCOã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™ã€‚

        ç”»åƒã®èª­ã¿è¾¼ã¿ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§ä¸¦åˆ—åŒ–ã—ã€
        å‡¦ç†æ™‚é–“ã‚’çŸ­ç¸®ã—ã¾ã™ã€‚ç”»åƒã®é †åºã¯ã‚¯ãƒªãƒƒãƒ—ã”ã¨ã€ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·é †ã«ç¶­æŒã•ã‚Œã¾ã™ã€‚

        Args:
            input_dir (Path): å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
            grouped_files (Dict[Tuple[int, int], List[Path]]): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€‚

        Returns:
            int: å‡¦ç†å¯¾è±¡ã®ç·ç”»åƒæ•°ã€‚
        """
        print("ğŸ–¼ï¸ ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã‚’é–‹å§‹ (é«˜é€ŸåŒ–ãƒãƒ¼ã‚¸ãƒ§ãƒ³)")

        # 1. å‡¦ç†é †åºã‚’ç¢ºå®šã•ã›ãŸå…¨ç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        sorted_group_keys = sorted(grouped_files.keys())
        ordered_paths = [path for key in sorted_group_keys for path in grouped_files[key]]
        total_images = len(ordered_paths)
        if total_images == 0:
            return 0

        # 2. çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’äº‹å‰ã«ç¢ºä¿
        self.coco_manager.coco_output['images'] = [None] * total_images
        # å…±æœ‰ãƒªã‚½ãƒ¼ã‚¹ã‚’ä¿è­·ã™ã‚‹ãŸã‚ã®ãƒ­ãƒƒã‚¯
        map_lock = threading.Lock()

        def _process_single_image(path: Path, index: int):
            """å˜ä¸€ã®ç”»åƒã‚’å‡¦ç†ã—ã¦COCOã‚¨ãƒ³ãƒˆãƒªã‚’ç”Ÿæˆã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•°ã€‚"""
            try:
                # ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€é«˜ã•ã¨å¹…ã‚’å–å¾—
                img = cv2.imread(str(path))
                if img is None:
                    print(f"è­¦å‘Š: ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {path}")
                    return None
                height, width = img.shape[:2]

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                game_id, clip_id = extract_ids_from_path(path)
                image_id = index + 1  # 1-based index

                # COCOç”»åƒã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
                rel_path = str(path.relative_to(input_dir))
                image_entry = {
                    "id": image_id, "file_name": path.name,
                    "original_path": rel_path, "height": height, "width": width,
                    "license": 1, "game_id": game_id, "clip_id": clip_id,
                }
                return index, image_entry, path, image_id
            except Exception as e:
                print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({path}): {e}")
                return None

        # 3. ThreadPoolExecutorã§ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=self.preprocess_workers) as executor:
            # ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒ–ãƒŸãƒƒãƒˆ
            futures = [
                executor.submit(_process_single_image, path, i)
                for i, path in enumerate(ordered_paths)
            ]

            with tqdm(total=total_images, desc="ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ç”Ÿæˆä¸­") as pbar:
                for future in futures:
                    result = future.result()
                    if result:
                        index, image_entry, path, image_id = result
                        # 4. äº‹å‰ã«ç¢ºä¿ã—ãŸãƒªã‚¹ãƒˆã®æ­£ã—ã„ä½ç½®ã«çµæœã‚’æ ¼ç´
                        self.coco_manager.coco_output['images'][index] = image_entry
                        # 5. å…±æœ‰ãƒãƒƒãƒ—ã‚’ãƒ­ãƒƒã‚¯ã—ã¦æ›´æ–°
                        with map_lock:
                            self.image_id_map[path] = image_id
                    pbar.update(1)

        # NoneãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆï¼ˆã‚¨ãƒ©ãƒ¼ã§å‡¦ç†ã§ããªã‹ã£ãŸç”»åƒï¼‰ã¯é™¤å»
        self.coco_manager.coco_output['images'] = [
            entry for entry in self.coco_manager.coco_output['images'] if entry is not None
        ]
        # æ¬¡ã®IDãŒæ­£ã—ããªã‚‹ã‚ˆã†ã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°
        self.coco_manager.image_id_counter = len(self.coco_manager.coco_output['images']) + 1

        # 6. æœ€å¾Œã«grouped_entriesã‚’æ§‹ç¯‰
        print("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€å‡¦ç†ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å†æ§‹ç¯‰ä¸­...")
        for group_key in sorted_group_keys:
            self.grouped_entries[group_key] = []
            for path in grouped_files[group_key]:
                if path in self.image_id_map:
                    img_id = self.image_id_map[path]
                    self.grouped_entries[group_key].append((img_id, path))

        final_image_count = len(self.coco_manager.coco_output['images'])
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†ã€‚æœ‰åŠ¹ãªç”»åƒæ•°: {final_image_count} / {total_images}")

        return final_image_count
    
    def _preload_clip(self, id_path_pairs: List[Tuple[int, Path]]):
        """ã‚¯ãƒªãƒƒãƒ—å†…ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸¦åˆ—ã§å…ˆèª­ã¿ã—ã¾ã™ã€‚"""
        frames, ids, paths = [], [], []
        with ThreadPoolExecutor() as executor:
            future_to_id_path = {executor.submit(load_frame, path): (img_id, path) for img_id, path in id_path_pairs}
            for future in future_to_id_path:
                frame = future.result()
                if frame is not None:
                    img_id, path = future_to_id_path[future]
                    frames.append(frame)
                    ids.append(img_id)
                    paths.append(path)
        return frames, ids, paths
    
    def _submit_tasks(self, frames: List, ids: List, paths: List, pbar: tqdm):
        """èª­ã¿è¾¼ã‚“ã ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒãƒƒãƒåŒ–ã—ã€å„å‰å‡¦ç†ã‚­ãƒ¥ãƒ¼ã«ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™ã€‚"""
        for name, worker in self.workers.items():
            batch_size = self.batch_sizes[name]
            for i in range(0, len(frames), batch_size):
                batch_end = i + batch_size
                batch_frames = frames[i:batch_end]
                batch_ids = ids[i:batch_end]
                batch_paths = paths[i:batch_end]
                
                meta_data = list(zip(batch_ids, batch_paths))
                task_id = f"{name}_{ids[i]}_{ids[min(batch_end, len(ids)-1)]}"
                task = PreprocessTask(task_id, batch_frames, meta_data)
                self.queues[name]["preprocess"].put(task)
        
        pbar.update(len(frames))

    def _wait_for_completion(self):
        """å…¨ã¦ã®ã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã‚‹ã¾ã§å¾…æ©Ÿã—ã¾ã™ã€‚"""
        all_queues = [q for spec in self.queues.values() for q in spec.values()]
        while any(not q.empty() for q in all_queues):
            time.sleep(1)
            if self.debug:
                for name, spec in self.queues.items():
                    print(f"[{name.upper()}] Queues "
                          f"Pre: {spec['preprocess'].qsize()}, "
                          f"Inf: {spec['inference'].qsize()}, "
                          f"Post: {spec['postprocess'].qsize()}")
        
        # task_done()ãŒå‘¼ã°ã‚Œã‚‹ã®ã‚’å¾…ã¤
        for spec in self.queues.values():
            for q in spec.values():
                q.join()

    def run(self, input_dir: Union[str, Path], output_json: Union[str, Path],
            image_extensions: List[str] = None):
        """ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        Args:
            input_dir (Union[str, Path]): å…¥åŠ›ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
            output_json (Union[str, Path]): å‡ºåŠ›COCO-JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚
            image_extensions (List[str], optional): å‡¦ç†å¯¾è±¡ã®ç”»åƒæ‹¡å¼µå­ã€‚
        """
        input_dir, output_json = Path(input_dir), Path(output_json)
        image_extensions = image_extensions or ['.jpg', '.jpeg', '.png']
        
        try:
            validate_paths(input_dir, output_json)
            grouped_files = collect_and_group_images(input_dir, image_extensions)
            if not grouped_files:
                raise ValueError("æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

            total_images = self._prepare_image_metadata(input_dir, grouped_files)
            
            self._start_workers()

            with tqdm(total=total_images, desc="ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ä¸­") as pbar:
                sorted_group_keys = sorted(grouped_files.keys())
                for idx, group_key in enumerate(sorted_group_keys):
                    game_id, clip_id = group_key
                    print(f"\nâ–¶ï¸ Clipå‡¦ç†é–‹å§‹: Game {game_id}, Clip {clip_id} ({idx+1}/{len(sorted_group_keys)})")
                    
                    # ãƒœãƒ¼ãƒ«ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    self.workers["ball"].reset_state()
                    
                    id_path_pairs = self.grouped_entries[group_key]
                    frames, ids, paths = self._preload_clip(id_path_pairs)
                    
                    if not frames:
                        print(f"è­¦å‘Š: Clipå†…ã«æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {group_key}")
                        pbar.update(len(id_path_pairs))
                        continue
                        
                    self._submit_tasks(frames, ids, paths, pbar)
            
            print("\nâ³ å…¨ã¦ã®ã‚¿ã‚¹ã‚¯æŠ•å…¥ãŒå®Œäº†ã€‚å‡¦ç†ã®å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
            self._wait_for_completion()

        except Exception as e:
            print(f"ğŸ’¥ å‡¦ç†ä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self._stop_workers()
            self.coco_manager.save_to_json(output_json)