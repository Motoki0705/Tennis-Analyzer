# multi_flow_annotator/annotator.py

import queue
import time
from pathlib import Path
from typing import List, Union, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor

from tqdm import tqdm
import cv2

from .definitions import PreprocessTask
from .coco_utils import CocoManager
from .file_utils import validate_paths, collect_and_group_images, load_frame
from .workers.ball_worker import BallWorker
from .workers.court_worker import CourtWorker
from .workers.pose_worker import PoseWorker

class MultiFlowAnnotator:
    """ãƒãƒ«ãƒãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ç”»åƒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹ç‡çš„ã«è¡Œã†ã‚¯ãƒ©ã‚¹ã€‚

    å‰å‡¦ç†ã€æ¨è«–ã€å¾Œå‡¦ç†ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¸¦åˆ—åŒ–ã—ã€GPUä½¿ç”¨ç‡ã®æœ€å¤§åŒ–ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
    ãƒ¡ã‚¤ãƒ³ã®è²¬å‹™ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®ç®¡ç†ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆ¶å¾¡ã€ã‚¿ã‚¹ã‚¯ã®æŠ•å…¥ã§ã™ã€‚
    """

    def __init__(
        self,
        ball_predictor, court_predictor, pose_predictor,
        batch_sizes: dict = None,
        vis_thresholds: dict = None,
        preprocess_workers: int = 4,
        max_queue_size: int = 8,
        debug: bool = False,
    ):
        """MultiFlowAnnotatorã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            ball_predictor: ãƒœãƒ¼ãƒ«æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å™¨ã€‚
            court_predictor: ã‚³ãƒ¼ãƒˆæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å™¨ã€‚
            pose_predictor: ãƒãƒ¼ã‚ºæ¨å®šãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å™¨ã€‚
            batch_sizes (dict): å„ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®šã€‚
            vis_thresholds (dict): å„ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯è¦–æ€§é–¾å€¤ã€‚
            preprocess_workers (int): ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿ãªã©å‰å‡¦ç†ç”¨ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã€‚
            max_queue_size (int): å„å‡¦ç†ã‚­ãƒ¥ãƒ¼ã®æœ€å¤§ã‚µã‚¤ã‚ºã€‚
            debug (bool): ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã€‚
        """
        self.batch_sizes = batch_sizes or {"ball": 8, "court": 8, "pose": 8}
        self.vis_thresholds = vis_thresholds or {"ball": 0.5, "court": 0.6, "pose": 0.5}
        self.max_queue_size = max_queue_size
        self.debug = debug
        
        self.coco_manager = CocoManager()
        self.image_id_map: Dict[Path, int] = {}
        self.grouped_entries: Dict[Tuple[int, int], List[Tuple[int, Path]]] = {}

        # å‡¦ç†ã‚­ãƒ¥ãƒ¼ã®åˆæœŸåŒ–
        self._initialize_queues()

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆæœŸåŒ–
        self.workers = {
            "ball": BallWorker(
                ball_predictor, self.queues["ball"]["preprocess"], self.queues["ball"]["inference"],
                self.queues["ball"]["postprocess"], self.coco_manager, self.vis_thresholds["ball"], self.debug
            ),
            "court": CourtWorker(
                court_predictor, self.queues["court"]["preprocess"], self.queues["court"]["inference"],
                self.queues["court"]["postprocess"], self.coco_manager, self.vis_thresholds["court"], self.debug
            ),
            "pose": PoseWorker(
                pose_predictor, self.queues["pose"]["preprocess"], self.queues["pose"]["inference"],
                self.queues["pose"]["postprocess"], self.coco_manager, self.vis_thresholds["pose"], self.debug
            ),
        }

    def _initialize_queues(self):
        """å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ã®ã‚­ãƒ¥ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        self.queues = {}
        for name in ["ball", "court", "pose"]:
            self.queues[name] = {
                "preprocess": queue.Queue(maxsize=self.max_queue_size),
                "inference": queue.Queue(maxsize=self.max_queue_size),
                "postprocess": queue.Queue(maxsize=self.max_queue_size),
            }

    def _start_workers(self):
        """å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚"""
        for worker in self.workers.values():
            worker.start()
        print("âœ… å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")

    def _stop_workers(self):
        """å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã™ã€‚"""
        print("\nâ³ ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®åœæ­¢å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        for worker in self.workers.values():
            worker.stop()
        print("âœ… å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")

    def _prepare_image_metadata(
        self, input_dir: Path, grouped_files: Dict[Tuple[int, int], List[Path]]
    ) -> int:
        """ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã€COCOã‚¨ãƒ³ãƒˆãƒªã‚’äº‹å‰ã«ä½œæˆã—ã¾ã™ã€‚

        Args:
            input_dir (Path): å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
            grouped_files (Dict[Tuple[int, int], List[Path]]): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€‚

        Returns:
            int: å‡¦ç†å¯¾è±¡ã®ç·ç”»åƒæ•°ã€‚
        """
        total_images = sum(len(files) for files in grouped_files.values())
        print(f"ğŸ–¼ï¸ ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã‚’é–‹å§‹: ç·æ•° {total_images}æš")

        with tqdm(total=total_images, desc="ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­") as pbar:
            for group_key, file_list in grouped_files.items():
                game_id, clip_id = group_key
                self.grouped_entries[group_key] = []
                for img_path in file_list:
                    try:
                        # ã‚µã‚¤ã‚ºå–å¾—ã®ãŸã‚ã«ä¸€åº¦ç”»åƒã‚’èª­ã¿è¾¼ã‚€
                        img = cv2.imread(str(img_path))
                        if img is None: continue
                        height, width = img.shape[:2]
                        
                        img_id = self.coco_manager.add_image_entry(
                            img_path, height, width, game_id, clip_id, input_dir
                        )
                        self.image_id_map[img_path] = img_id
                        self.grouped_entries[group_key].append((img_id, img_path))
                    except Exception as e:
                        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {img_path}, {e}")
                    finally:
                        pbar.update(1)
        
        return total_images

    def _preload_clip(self, id_path_pairs: List[Tuple[int, Path]]):
        """ã‚¯ãƒªãƒƒãƒ—å†…ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸¦åˆ—ã§å…ˆèª­ã¿ã—ã¾ã™ã€‚"""
        frames, ids, paths = [], [], []
        with ThreadPoolExecutor() as executor:
            future_to_id_path = {executor.submit(load_frame, path): (img_id, path) for img_id, path in id_path_pairs}
            for future in future_to_id_path:
                frame = future.result()
                if frame is not None:
                    img_id, path = future_to_id_path[future]
                    frames.append(frame)
                    ids.append(img_id)
                    paths.append(path)
        return frames, ids, paths
    
    def _submit_tasks(self, frames: List, ids: List, paths: List, pbar: tqdm):
        """èª­ã¿è¾¼ã‚“ã ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒãƒƒãƒåŒ–ã—ã€å„å‰å‡¦ç†ã‚­ãƒ¥ãƒ¼ã«ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™ã€‚"""
        for name, worker in self.workers.items():
            batch_size = self.batch_sizes[name]
            for i in range(0, len(frames), batch_size):
                batch_end = i + batch_size
                batch_frames = frames[i:batch_end]
                batch_ids = ids[i:batch_end]
                batch_paths = paths[i:batch_end]
                
                meta_data = list(zip(batch_ids, batch_paths))
                task_id = f"{name}_{ids[i]}_{ids[min(batch_end, len(ids)-1)]}"
                task = PreprocessTask(task_id, batch_frames, meta_data)
                self.queues[name]["preprocess"].put(task)
        
        pbar.update(len(frames))

    def _wait_for_completion(self):
        """å…¨ã¦ã®ã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã‚‹ã¾ã§å¾…æ©Ÿã—ã¾ã™ã€‚"""
        all_queues = [q for spec in self.queues.values() for q in spec.values()]
        while any(not q.empty() for q in all_queues):
            time.sleep(1)
            if self.debug:
                for name, spec in self.queues.items():
                    print(f"[{name.upper()}] Queues "
                          f"Pre: {spec['preprocess'].qsize()}, "
                          f"Inf: {spec['inference'].qsize()}, "
                          f"Post: {spec['postprocess'].qsize()}")
        
        # task_done()ãŒå‘¼ã°ã‚Œã‚‹ã®ã‚’å¾…ã¤
        for spec in self.queues.values():
            for q in spec.values():
                q.join()

    def run(self, input_dir: Union[str, Path], output_json: Union[str, Path],
            image_extensions: List[str] = None):
        """ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        Args:
            input_dir (Union[str, Path]): å…¥åŠ›ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
            output_json (Union[str, Path]): å‡ºåŠ›COCO-JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚
            image_extensions (List[str], optional): å‡¦ç†å¯¾è±¡ã®ç”»åƒæ‹¡å¼µå­ã€‚
        """
        input_dir, output_json = Path(input_dir), Path(output_json)
        image_extensions = image_extensions or ['.jpg', '.jpeg', '.png']
        
        try:
            validate_paths(input_dir, output_json)
            grouped_files = collect_and_group_images(input_dir, image_extensions)
            if not grouped_files:
                raise ValueError("æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

            total_images = self._prepare_image_metadata(input_dir, grouped_files)
            
            self._start_workers()

            with tqdm(total=total_images, desc="ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ä¸­") as pbar:
                sorted_group_keys = sorted(grouped_files.keys())
                for idx, group_key in enumerate(sorted_group_keys):
                    game_id, clip_id = group_key
                    print(f"\nâ–¶ï¸ Clipå‡¦ç†é–‹å§‹: Game {game_id}, Clip {clip_id} ({idx+1}/{len(sorted_group_keys)})")
                    
                    # ãƒœãƒ¼ãƒ«ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    self.workers["ball"].reset_state()
                    
                    id_path_pairs = self.grouped_entries[group_key]
                    frames, ids, paths = self._preload_clip(id_path_pairs)
                    
                    if not frames:
                        print(f"è­¦å‘Š: Clipå†…ã«æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {group_key}")
                        pbar.update(len(id_path_pairs))
                        continue
                        
                    self._submit_tasks(frames, ids, paths, pbar)
            
            print("\nâ³ å…¨ã¦ã®ã‚¿ã‚¹ã‚¯æŠ•å…¥ãŒå®Œäº†ã€‚å‡¦ç†ã®å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
            self._wait_for_completion()

        except Exception as e:
            print(f"ğŸ’¥ å‡¦ç†ä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self._stop_workers()
            self.coco_manager.save_to_json(output_json)