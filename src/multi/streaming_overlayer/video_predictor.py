# streaming_annotator/video_predictor.py

import queue
import time
import threading
from pathlib import Path
from typing import Dict, List, Union, Any, Optional
from concurrent.futures import ThreadPoolExecutor

import cv2
import numpy as np
from tqdm import tqdm

from .definitions import PreprocessTask
from .video_utils import FrameLoader
from .workers.base_worker import BaseWorker
from .workers.ball_worker import BallWorker
from .workers.court_worker import CourtWorker
from .workers.pose_worker import PoseWorker
from .queue_manager import QueueManager, create_queue_manager_for_video_predictor
from .config_utils import (
    create_queue_configs_from_hydra_config,
    get_worker_extended_queue_names,
    apply_performance_settings,
    validate_queue_config,
    log_queue_configuration
)

class VideoPredictor:
    """
    å‹•ç”»ã«å¯¾ã—ã¦è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€çµæœã‚’æç”»ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    
    multi_flow_annotatorã‚’å‚è€ƒã«ã€å‰å‡¦ç†ãƒ»æ¨è«–ãƒ»å¾Œå‡¦ç†ã®ãƒãƒ«ãƒãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Ÿè£…ã—ã€
    GPUä½¿ç”¨åŠ¹ç‡ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        ball_predictor, court_predictor, pose_predictor,
        intervals: Dict[str, int], batch_sizes: Dict[str, int],
        debug: bool = False,
        custom_queue_configs: Optional[Dict[str, Dict[str, Any]]] = None,
        hydra_queue_config: Optional[Any] = None,
        max_preload_frames: int = 64,  # ãƒ•ãƒ¬ãƒ¼ãƒ å…ˆèª­ã¿æ•°
        enable_performance_monitoring: bool = True  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    ):
        self.predictors = {
            "ball": ball_predictor,
            "court": court_predictor,
            "pose": pose_predictor,
        }
        self.intervals = intervals
        self.batch_sizes = batch_sizes
        self.debug = debug
        self.max_preload_frames = max_preload_frames
        self.enable_performance_monitoring = enable_performance_monitoring

        # æ‹¡å¼µå¯èƒ½ãªã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        worker_names = list(self.predictors.keys())
        
        # Hydraè¨­å®šã‹ã‚‰ã‚­ãƒ¥ãƒ¼ã‚³ãƒ³ãƒ•ã‚£ã‚°ã‚’ä½œæˆ
        if hydra_queue_config is not None:
            try:
                # è¨­å®šæ¤œè¨¼
                if validate_queue_config(hydra_queue_config):
                    log_queue_configuration(hydra_queue_config)
                    
                    # Hydraè¨­å®šã‚’QueueManagerå½¢å¼ã«å¤‰æ›
                    queue_configs_from_hydra = create_queue_configs_from_hydra_config(hydra_queue_config)
                    
                    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã¨ãƒãƒ¼ã‚¸
                    final_queue_configs = queue_configs_from_hydra.copy()
                    if custom_queue_configs:
                        final_queue_configs.update(custom_queue_configs)
                    
                    self.queue_manager = create_queue_manager_for_video_predictor(
                        worker_names, 
                        final_queue_configs
                    )
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šã‚’é©ç”¨
                    performance_settings = apply_performance_settings(hydra_queue_config)
                    self._apply_performance_settings(performance_settings)
                    
                else:
                    raise ValueError("Hydra ã‚­ãƒ¥ãƒ¼è¨­å®šã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
            except Exception as e:
                print(f"âš ï¸ Hydraè¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                print("ğŸ”„ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                self.queue_manager = create_queue_manager_for_video_predictor(
                    worker_names, 
                    custom_queue_configs
                )
        else:
            self.queue_manager = create_queue_manager_for_video_predictor(
                worker_names, 
                custom_queue_configs
            )

        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆæœŸåŒ–
        self.workers = self._initialize_workers()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«
        self.frame_processing_pool = ThreadPoolExecutor(
            max_workers=4, 
            thread_name_prefix="frame_processor"
        )
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šã‚’ã“ã“ã§åˆæœŸåŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
        self.performance_settings = {"enable_monitoring": True}
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.performance_metrics = {
            "total_frames_processed": 0,
            "total_processing_time": 0.0,
            "frames_per_second": 0.0,
            "queue_throughput": {},
            "worker_performance": {},
            "start_time": None,
            "end_time": None
        }
        
        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ï¼ˆãƒœãƒ¼ãƒ«ç”¨ï¼‰
        self.sliding_windows = {}
        self.sliding_window_lock = threading.Lock()
    
    def _apply_performance_settings(self, settings: Dict[str, Any]):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šã‚’é©ç”¨"""
        self.performance_settings.update(settings)
        
        if settings.get('enable_monitoring', False):
            print("ğŸ“Š ã‚­ãƒ¥ãƒ¼ç›£è¦–æ©Ÿèƒ½ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
        
        if settings.get('log_queue_status', False):
            print("ğŸ“ ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹ãƒ­ã‚°å‡ºåŠ›ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
        
        if settings.get('gpu_optimization', False):
            print("ğŸš€ GPUæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def get_queue_status_with_settings(self) -> Dict[str, Any]:
        """è¨­å®šã«åŸºã¥ã„ã¦ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹ã‚’å–å¾—"""
        if not self.performance_settings.get('enable_monitoring', True):
            return {"monitoring": "disabled"}
        
        status = self.queue_manager.get_queue_status()
        
        if self.performance_settings.get('log_queue_status', False):
            print("ğŸ“Š Queue Status:")
            print(f"  Results queue: {status['results_queue_size']} items")
            for worker, info in status['workers'].items():
                print(f"  {worker}: {sum(info['base_queues'].values())} base + {sum(info['extended_queues'].values())} extended")
        
        return status

    def _initialize_workers(self) -> Dict[str, "BaseWorker"]:
        """å„ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        workers = {}
        
        # æ­£ã—ã„ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’å‰²ã‚Šå½“ã¦
        worker_classes = {
            "ball": BallWorker,
            "court": CourtWorker,
            "pose": PoseWorker,
        }

        for name, pred in self.predictors.items():
            worker_class = worker_classes.get(name, BaseWorker)
            
            # QueueManagerã‹ã‚‰ã‚­ãƒ¥ãƒ¼ã‚»ãƒƒãƒˆã‚’å–å¾—
            queue_set = self.queue_manager.get_worker_queue_set(name)
            if not queue_set:
                raise ValueError(f"Queue set for worker '{name}' not found")
            
            workers[name] = worker_class(
                name,
                pred,
                queue_set,  # ã‚­ãƒ¥ãƒ¼ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æ¸¡ã™
                self.queue_manager.get_results_queue(),
                self.debug,
            )
        return workers

    def run(self, input_path: Union[str, Path], output_path: Union[str, Path]):
        """å‹•ç”»å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"""
        input_path, output_path = Path(input_path), Path(output_path)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹
        self.performance_metrics["start_time"] = time.time()

        try:
            # 1. I/Oã¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            frame_loader = FrameLoader(input_path).start()
            props = frame_loader.get_properties()
            writer = cv2.VideoWriter(
                str(output_path), 
                cv2.VideoWriter_fourcc(*"mp4v"), 
                props["fps"], 
                (props["width"], props["height"])
            )
            
            for worker in self.workers.values():
                worker.start()

            # 2. ãƒ•ãƒ¬ãƒ¼ãƒ æŠ•å…¥ (Dispatcher) - ä¸¦åˆ—åŒ–
            self._dispatch_frames_parallel(frame_loader, props["total_frames"])

            # 3. çµæœã®é›†ç´„ã¨æç”»
            self._aggregate_and_write_results(writer, input_path, props["total_frames"])
            
            # 4. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            for worker in self.workers.values():
                worker.stop()
            frame_loader.release()
            writer.release()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–çµ‚äº†
            self.performance_metrics["end_time"] = time.time()
            self._finalize_performance_metrics()
            
            print(f"âœ… å‡¦ç†å®Œäº† â†’ å‡ºåŠ›å‹•ç”»: {output_path}")
            
            if self.enable_performance_monitoring:
                self._print_performance_summary()
                
        except Exception as e:
            print(f"âŒ å‹•ç”»å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            for worker in self.workers.values():
                worker.stop()
            if 'frame_loader' in locals():
                frame_loader.release()
            if 'writer' in locals():
                writer.release()
        finally:
            # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã®çµ‚äº†
            self.frame_processing_pool.shutdown(wait=True)

    def _dispatch_frames_parallel(self, frame_loader: FrameLoader, total_frames: int):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸¦åˆ—ã§èª­ã¿è¾¼ã¿ã€é©åˆ‡ãªé–“éš”ã§å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™ã€‚"""
        buffers = {name: [] for name in self.predictors}
        meta_buffers = {name: [] for name in self.predictors}
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ å…ˆèª­ã¿ãƒãƒƒãƒ•ã‚¡
        preload_buffer = []
        
        print("ğŸš€ ä¸¦åˆ—ãƒ•ãƒ¬ãƒ¼ãƒ æŠ•å…¥ã‚’é–‹å§‹...")
        with tqdm(total=total_frames, desc="ãƒ•ãƒ¬ãƒ¼ãƒ æŠ•å…¥ä¸­") as pbar:
            frame_count = 0
            
            while frame_count < total_frames:
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã®å…ˆèª­ã¿
                frames_to_read = min(self.max_preload_frames, total_frames - frame_count)
                
                # ä¸¦åˆ—ã§ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
                future_frames = []
                for _ in range(frames_to_read):
                    data = frame_loader.read()
                    if data is None:
                        break
                    future_frames.append(data)
                    frame_count += 1
                
                if not future_frames:
                    break
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ
                processing_futures = []
                for frame_idx, frame in future_frames:
                    future = self.frame_processing_pool.submit(
                        self._process_single_frame, 
                        frame_idx, frame, buffers.copy(), meta_buffers.copy()
                    )
                    processing_futures.append((frame_idx, future))
                
                # å‡¦ç†çµæœã‚’åé›†
                for frame_idx, future in processing_futures:
                    try:
                        frame_buffers, frame_meta_buffers = future.result(timeout=1.0)
                        
                        # ãƒãƒƒãƒ•ã‚¡ã‚’æ›´æ–°
                        for name in self.predictors:
                            if frame_buffers[name]:
                                buffers[name].extend(frame_buffers[name])
                                meta_buffers[name].extend(frame_meta_buffers[name])
                            
                            # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
                            if len(buffers[name]) >= self.batch_sizes[name]:
                                self._create_and_submit_task(
                                    name, frame_idx, buffers[name], meta_buffers[name]
                                )
                                buffers[name].clear()
                                meta_buffers[name].clear()
                                
                    except Exception as e:
                        print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {frame_idx}, {e}")
                        if self.debug:
                            import traceback
                            traceback.print_exc()
                
                pbar.update(len(future_frames))

        # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã€ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
        for name in self.predictors:
            if buffers[name]:
                self._create_and_submit_task(
                    name, frame_count, buffers[name], meta_buffers[name]
                )

    def _process_single_frame(self, frame_idx: int, frame: np.ndarray, buffers: Dict, meta_buffers: Dict) -> tuple:
        """å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã—ã€é©åˆ‡ãªãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã¾ã™ã€‚"""
        frame_buffers = {name: [] for name in self.predictors}
        frame_meta_buffers = {name: [] for name in self.predictors}
        
        for name, interval in self.intervals.items():
            if frame_idx % interval == 0:
                frame_buffers[name].append(frame)
                frame_meta_buffers[name].append((frame_idx, frame.shape[0], frame.shape[1]))
        
        return frame_buffers, frame_meta_buffers
    
    def _create_and_submit_task(self, name: str, frame_idx: int, frames: List, meta_data: List):
        """ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¦ã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥ã—ã¾ã™ã€‚"""
        task = PreprocessTask(f"{name}_{frame_idx}", frames.copy(), meta_data.copy())
        preprocess_queue = self.queue_manager.get_queue(name, "preprocess")
        preprocess_queue.put(task)
        
        if self.debug:
            print(f"ğŸ“‹ ã‚¿ã‚¹ã‚¯æŠ•å…¥: {name}, frames={len(frames)}")

    def _dispatch_frames(self, frame_loader: FrameLoader, total_frames: int):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã¿ã€é©åˆ‡ãªé–“éš”ã§å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™ã€‚ï¼ˆæ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        buffers = {name: [] for name in self.predictors}
        meta_buffers = {name: [] for name in self.predictors}
        
        print("ğŸš€ ãƒ•ãƒ¬ãƒ¼ãƒ ã®æŠ•å…¥ã‚’é–‹å§‹...")
        with tqdm(total=total_frames, desc="ãƒ•ãƒ¬ãƒ¼ãƒ æŠ•å…¥ä¸­") as pbar:
            while True:
                data = frame_loader.read()
                if data is None: break # å‹•ç”»ã®çµ‚ç«¯
                
                frame_idx, frame = data
                
                for name, interval in self.intervals.items():
                    if frame_idx % interval == 0:
                        buffers[name].append(frame)
                        meta_buffers[name].append((frame_idx, frame.shape[0], frame.shape[1])) # (idx, H, W)
                
                    if len(buffers[name]) >= self.batch_sizes[name]:
                        task = PreprocessTask(f"{name}_{frame_idx}", buffers[name], meta_buffers[name])
                        preprocess_queue = self.queue_manager.get_queue(name, "preprocess")
                        preprocess_queue.put(task)
                        buffers[name].clear()
                        meta_buffers[name].clear()
                pbar.update(1)

        # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã€ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
        for name in self.predictors:
            if buffers[name]:
                task = PreprocessTask(f"{name}_final", buffers[name], meta_buffers[name])
                preprocess_queue = self.queue_manager.get_queue(name, "preprocess")
                preprocess_queue.put(task)

    def _aggregate_and_write_results(self, writer: cv2.VideoWriter, input_path: Path, total_frames: int):
        """çµæœã‚­ãƒ¥ãƒ¼ã‹ã‚‰æ¨è«–çµæœã‚’é›†ç´„ã—ã€æç”»ã—ã¦å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã™ã€‚"""
        cached_preds = {name: None for name in self.predictors}
        results_by_frame: Dict[int, Dict[str, Any]] = {}
        
        # VideoCaptureã‚’ã‚‚ã†ä¸€åº¦é–‹ã„ã¦æç”»ç”¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
        cap = cv2.VideoCapture(str(input_path))

        print("âœï¸ çµæœã®é›†ç´„ã¨å‹•ç”»æ›¸ãè¾¼ã¿ã‚’é–‹å§‹...")
        with tqdm(total=total_frames, desc="å‹•ç”»æ›¸ãè¾¼ã¿ä¸­") as pbar:
            for frame_idx in range(total_frames):
                # ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¾ã§ã®çµæœã‚’ã™ã¹ã¦ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–ã‚Šå‡ºã™
                results_queue = self.queue_manager.get_results_queue()
                timeout_count = 0
                max_timeout = 10  # æœ€å¤§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå›æ•°
                
                while timeout_count < max_timeout:
                    try:
                        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–å¾—
                        if not results_queue.empty() and results_queue.queue[0][0] <= frame_idx:
                            res_idx, name, result = results_queue.get(timeout=0.1)
                            if res_idx not in results_by_frame:
                                results_by_frame[res_idx] = {}
                            results_by_frame[res_idx][name] = result
                        else:
                            break
                    except queue.Empty:
                        timeout_count += 1
                        if timeout_count >= max_timeout:
                            if self.debug:
                                print(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_idx}: çµæœå–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                            break

                # æç”»ç”¨ã®ç”Ÿãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                ret, frame = cap.read()
                if not ret: break

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
                if frame_idx in results_by_frame:
                    for name, result in results_by_frame[frame_idx].items():
                        cached_preds[name] = result
                    del results_by_frame[frame_idx] # ãƒ¡ãƒ¢ãƒªè§£æ”¾

                # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»
                annotated_frame = frame.copy()
                for name, pred in cached_preds.items():
                    if pred is not None:
                        # Ball ãªã© list ãŒè¿”ã‚‹å ´åˆã¯ 1 ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã‚’æƒ³å®šã—ã¦ 0 ç•ªç›®ã‚’ä½¿ç”¨
                        to_draw = pred[0] if isinstance(pred, list) else pred
                        try:
                            annotated_frame = self.predictors[name].overlay(annotated_frame, to_draw)
                        except Exception:
                            # overlay å¤±æ•—æ™‚ã¯æç”»ã‚’ã‚¹ã‚­ãƒƒãƒ—
                            pass

                writer.write(annotated_frame)
                pbar.update(1)
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
                self.performance_metrics["total_frames_processed"] += 1
        
        cap.release()
    
    def _finalize_performance_metrics(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æœ€çµ‚åŒ–ã—ã¾ã™ã€‚"""
        if self.performance_metrics["start_time"] and self.performance_metrics["end_time"]:
            total_time = self.performance_metrics["end_time"] - self.performance_metrics["start_time"]
            self.performance_metrics["total_processing_time"] = total_time
            
            if total_time > 0:
                self.performance_metrics["frames_per_second"] = (
                    self.performance_metrics["total_frames_processed"] / total_time
                )
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’åé›†
        for name, worker in self.workers.items():
            if hasattr(worker, 'get_performance_stats'):
                self.performance_metrics["worker_performance"][name] = worker.get_performance_stats()
    
    def _print_performance_summary(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¦‚è¦ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚"""
        metrics = self.performance_metrics
        
        print("\n" + "="*50)
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*50)
        print(f"ç·å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {metrics['total_frames_processed']}")
        print(f"ç·å‡¦ç†æ™‚é–“: {metrics['total_processing_time']:.2f} ç§’")
        print(f"å¹³å‡FPS: {metrics['frames_per_second']:.2f}")
        
        if metrics["worker_performance"]:
            print("\nğŸ”§ ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
            for worker_name, stats in metrics["worker_performance"].items():
                print(f"  {worker_name}:")
                for key, value in stats.items():
                    print(f"    {key}: {value}")
        
        # ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹ã‚’è¡¨ç¤º
        queue_status = self.get_queue_status_with_settings()
        if queue_status.get("monitoring") != "disabled":
            print(f"\nğŸ“‹ æœ€çµ‚ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹:")
            print(f"  çµæœã‚­ãƒ¥ãƒ¼: {queue_status.get('results_queue_size', 'N/A')} items")
        
        print("="*50 + "\n")

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        return self.performance_metrics.copy()