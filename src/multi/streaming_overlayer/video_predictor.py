# streaming_annotator/video_predictor.py

import queue
import time
from pathlib import Path
from typing import Dict, List, Union, Any, Optional

import cv2
import numpy as np
from tqdm import tqdm

from .definitions import PreprocessTask
from .video_utils import FrameLoader
from .workers.base_worker import BaseWorker
from .workers.ball_worker import BallWorker
from .workers.court_worker import CourtWorker
from .workers.pose_worker import PoseWorker
from .queue_manager import QueueManager, create_queue_manager_for_video_predictor

class VideoPredictor:
    """å‹•ç”»ã«å¯¾ã—ã¦è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€çµæœã‚’æç”»ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""

    def __init__(
        self,
        ball_predictor, court_predictor, pose_predictor,
        intervals: Dict[str, int], batch_sizes: Dict[str, int],
        debug: bool = False,
        custom_queue_configs: Optional[Dict[str, Dict[str, Any]]] = None
    ):
        self.predictors = {
            "ball": ball_predictor,
            "court": court_predictor,
            "pose": pose_predictor,
        }
        self.intervals = intervals
        self.batch_sizes = batch_sizes
        self.debug = debug

        # æ‹¡å¼µå¯èƒ½ãªã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        worker_names = list(self.predictors.keys())
        self.queue_manager = create_queue_manager_for_video_predictor(
            worker_names, 
            custom_queue_configs
        )

        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆæœŸåŒ–
        self.workers = self._initialize_workers()

    def _initialize_workers(self) -> Dict[str, "BaseWorker"]:
        """å„ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        workers = {}
        
        # æ­£ã—ã„ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’å‰²ã‚Šå½“ã¦
        worker_classes = {
            "ball": BallWorker,
            "court": CourtWorker,
            "pose": PoseWorker,
        }

        for name, pred in self.predictors.items():
            worker_class = worker_classes.get(name, BaseWorker)
            
            # QueueManagerã‹ã‚‰ã‚­ãƒ¥ãƒ¼ã‚»ãƒƒãƒˆã‚’å–å¾—
            queue_set = self.queue_manager.get_worker_queue_set(name)
            if not queue_set:
                raise ValueError(f"Queue set for worker '{name}' not found")
            
            workers[name] = worker_class(
                name,
                pred,
                queue_set,  # ã‚­ãƒ¥ãƒ¼ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æ¸¡ã™
                self.queue_manager.get_results_queue(),
                self.debug,
            )
        return workers

    def run(self, input_path: Union[str, Path], output_path: Union[str, Path]):
        """å‹•ç”»å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"""
        input_path, output_path = Path(input_path), Path(output_path)

        # 1. I/Oã¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        frame_loader = FrameLoader(input_path).start()
        props = frame_loader.get_properties()
        writer = cv2.VideoWriter(str(output_path), cv2.VideoWriter_fourcc(*"mp4v"), props["fps"], (props["width"], props["height"]))
        
        for worker in self.workers.values():
            worker.start()

        # 2. ãƒ•ãƒ¬ãƒ¼ãƒ æŠ•å…¥ (Dispatcher)
        self._dispatch_frames(frame_loader, props["total_frames"])

        # 3. çµæœã®é›†ç´„ã¨æç”»
        self._aggregate_and_write_results(writer, input_path, props["total_frames"])
        
        # 4. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for worker in self.workers.values():
            worker.stop()
        frame_loader.release()
        writer.release()
        print(f"âœ… å‡¦ç†å®Œäº† â†’ å‡ºåŠ›å‹•ç”»: {output_path}")

    def _dispatch_frames(self, frame_loader: FrameLoader, total_frames: int):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã¿ã€é©åˆ‡ãªé–“éš”ã§å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥ã—ã¾ã™ã€‚"""
        buffers = {name: [] for name in self.predictors}
        meta_buffers = {name: [] for name in self.predictors}
        
        print("ğŸš€ ãƒ•ãƒ¬ãƒ¼ãƒ ã®æŠ•å…¥ã‚’é–‹å§‹...")
        with tqdm(total=total_frames, desc="ãƒ•ãƒ¬ãƒ¼ãƒ æŠ•å…¥ä¸­") as pbar:
            while True:
                data = frame_loader.read()
                if data is None: break # å‹•ç”»ã®çµ‚ç«¯
                
                frame_idx, frame = data
                
                for name, interval in self.intervals.items():
                    if frame_idx % interval == 0:
                        buffers[name].append(frame)
                        meta_buffers[name].append((frame_idx, frame.shape[0], frame.shape[1])) # (idx, H, W)
                
                    if len(buffers[name]) >= self.batch_sizes[name]:
                        task = PreprocessTask(f"{name}_{frame_idx}", buffers[name], meta_buffers[name])
                        preprocess_queue = self.queue_manager.get_queue(name, "preprocess")
                        preprocess_queue.put(task)
                        buffers[name].clear()
                        meta_buffers[name].clear()
                pbar.update(1)

        # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã€ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
        for name in self.predictors:
            if buffers[name]:
                task = PreprocessTask(f"{name}_final", buffers[name], meta_buffers[name])
                preprocess_queue = self.queue_manager.get_queue(name, "preprocess")
                preprocess_queue.put(task)

    def _aggregate_and_write_results(self, writer: cv2.VideoWriter, input_path: Path, total_frames: int):
        """çµæœã‚­ãƒ¥ãƒ¼ã‹ã‚‰æ¨è«–çµæœã‚’é›†ç´„ã—ã€æç”»ã—ã¦å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã™ã€‚"""
        cached_preds = {name: None for name in self.predictors}
        results_by_frame: Dict[int, Dict[str, Any]] = {}
        
        # VideoCaptureã‚’ã‚‚ã†ä¸€åº¦é–‹ã„ã¦æç”»ç”¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
        cap = cv2.VideoCapture(str(input_path))

        print("âœï¸ çµæœã®é›†ç´„ã¨å‹•ç”»æ›¸ãè¾¼ã¿ã‚’é–‹å§‹...")
        with tqdm(total=total_frames, desc="å‹•ç”»æ›¸ãè¾¼ã¿ä¸­") as pbar:
            for frame_idx in range(total_frames):
                # ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¾ã§ã®çµæœã‚’ã™ã¹ã¦ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–ã‚Šå‡ºã™
                results_queue = self.queue_manager.get_results_queue()
                while not results_queue.empty() and results_queue.queue[0][0] <= frame_idx:
                    res_idx, name, result = results_queue.get()
                    if res_idx not in results_by_frame:
                        results_by_frame[res_idx] = {}
                    results_by_frame[res_idx][name] = result

                # æç”»ç”¨ã®ç”Ÿãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                ret, frame = cap.read()
                if not ret: break

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
                if frame_idx in results_by_frame:
                    for name, result in results_by_frame[frame_idx].items():
                        cached_preds[name] = result
                    del results_by_frame[frame_idx] # ãƒ¡ãƒ¢ãƒªè§£æ”¾

                # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»
                annotated_frame = frame.copy()
                for name, pred in cached_preds.items():
                    if pred is not None:
                        # Ball ãªã© list ãŒè¿”ã‚‹å ´åˆã¯ 1 ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã‚’æƒ³å®šã—ã¦ 0 ç•ªç›®ã‚’ä½¿ç”¨
                        to_draw = pred[0] if isinstance(pred, list) else pred
                        try:
                            annotated_frame = self.predictors[name].overlay(annotated_frame, to_draw)
                        except Exception:
                            # overlay å¤±æ•—æ™‚ã¯æç”»ã‚’ã‚¹ã‚­ãƒƒãƒ—
                            pass

                writer.write(annotated_frame)
                pbar.update(1)
        
        cap.release()