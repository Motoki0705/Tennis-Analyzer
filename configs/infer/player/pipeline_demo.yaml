# @package _global_

# Hydra configuration for player detection pipeline demo
hydra:
  output_subdir: hydra_outputs/${now:%Y-%m-%d_%H-%M-%S}
  run:
    dir: outputs/infer/player/pipeline_demo/${now:%Y-%m-%d_%H-%M-%S}

# Default configuration
defaults:
  - _self_

# Task identifier
task: player

# Input/Output settings
io:
  video: null  # Path to the input video (required)
  output: "demo_output_player.mp4"  # Output video file with detections
  results_csv: "player_detections.csv"  # Output CSV file for detection data

# Device configuration
device: auto  # Device to use: cuda, cpu, auto

# Processing configuration
batch_size: 32  # Batch size for inference

# Player detection model configuration
player:
  checkpoint_path: "checkpoints/best_model.ckpt"  # Path to the trained model checkpoint (.ckpt)
  score_threshold: 0.7  # Minimum score to visualize a detection
  
# Detection configuration
detection:
  # Label mapping for detection classes
  id2label:
    0: "player"
    1: "ball" 
    2: "referee"
  # NMS configuration
  nms_threshold: 0.5
  max_detections: 100

# Visualization settings
visualization:
  enabled: true
  draw_boxes: true
  draw_labels: true
  draw_scores: true
  box_thickness: 2
  font_scale: 0.7
  font_thickness: 2
  colors:
    player: [36, 255, 12]    # Green for player boxes
    ball: [0, 0, 255]        # Red for ball boxes
    referee: [255, 255, 0]   # Yellow for referee boxes
    text_bg: [36, 255, 12]   # Green for text background
    text: [0, 0, 0]          # Black for text

# Threading configuration
threading:
  num_workers: 3  # Number of worker threads
  queue_size_multiplier: 2  # Queue size = batch_size * this value

# Performance monitoring
performance:
  track_timings: true
  report_interval: 100  # Report performance every N frames

# Logging configuration
logging:
  level: INFO
  format: "%(asctime)s - %(levelname)s - %(message)s"