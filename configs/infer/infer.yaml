defaults:
  - _self_
  - ball: lite_tracknet      # lite_tracknet, swin_448
  - court: lite_tracknet_1heat     # lite_tracknet, lite_tracknet_1heat
  - player: rt_detr          # rt_detr
  - pose: vitpose       # vitpose
  - event: transformer   # 追加: イベント検出モデル


hydra:
  run:
    dir: hydra_outputs/infer/${mode}/${now:%Y-%m-%d_%H-%M-%S}

# --- Top-level Parameters ---
mode: "court" # ball, court, player, pose, event, multi, frames, image, streaming_overlayer, multi_event

# --- Common Settings ---
common:
  device: "cuda"
  use_half: true
  batch_size: 32

# --- Paths ---
input_path: "datasets/test/video_input2.mp4" # Override this
output_path: "outputs/${mode}/${now:%Y-%m-%d_%H-%M-%S}.mp4"
output_json_path: "outputs/${mode}/${now:%Y-%m-%d_%H-%M-%S}.json"

# --- Processors Configurations (these don't change often based on model variant) ---
processors:
  player:
    _target_: transformers.AutoImageProcessor.from_pretrained
    pretrained_model_name_or_path: "PekingU/rtdetr_v2_r18vd"
  pose:
    _target_: transformers.AutoImageProcessor.from_pretrained
    pretrained_model_name_or_path: "usyd-community/vitpose-base-simple" # Example, match your pose model

# --- Predictors Configurations (these now take instantiated models) ---
predictors:
  ball:
    _target_: src.ball.predictor.BallPredictor
    # Model is passed by main.py
    input_size: [360, 640] # These params are still needed by the predictor for pre/post processing
    heatmap_size: [360, 640]
    num_frames: 3 # Specific to the model type (e.g. LiteBallTracker needs 3)
    threshold: 0.7
    visualize_mode: "overlay"
  
  court:
    _target_: src.court.predictor.CourtPredictor
    input_size: [360, 640]
    num_keypoints: 15 # This might be specific to the model's output head (e.g. FPN outputs 1 channel)
    threshold: 0.6
    visualize_mode: "overlay"

  player:
    _target_: src.player.predictor.PlayerPredictor
    # model & processor are passed by main.py
    label_map: {0: "player"} # Adjust based on your player_detector model
    threshold: 0.7

  pose:
    _target_: src.pose.predictor.PosePredictor
    # det_model, det_processor, pose_model, pose_processor passed by main.py
    player_label_id: 0 # Label ID for 'person' in the detection model
    det_score_thresh: 0.7
    pose_score_thresh: 0.7

  multi:
    _target_: src.multi.multi_predictor.MultiPredictor
    # ball_predictor, court_predictor, pose_predictor are instantiated and passed by main.py
    ball_interval: 1
    court_interval: 1
    pose_interval: 1
    ball_batch_size: 16  # Default to 1 if not specified, matching old behavior
    court_batch_size: 16
    pose_batch_size: 16

  frames_annotator:
    _target_: src.multi.frames_predictor.FrameAnnotator
    # ball_predictor, court_predictor, pose_predictor are instantiated and passed by main.py
    intervals: {"ball": 1, "court": 1, "pose": 1}
    batch_sizes: {"ball": 16, "court": 16, "pose": 16}
    frame_fmt: "frame_{:06d}.jpg"
    
  # 画像アノテータ設定（新規追加）
  image_annotator:
    # ball_predictor, court_predictor, pose_predictor は main.py で渡される
    batch_sizes: {"ball": 16, "court": 16, "pose": 16}
    ball_vis_thresh: ${predictors.ball.threshold}
    court_vis_thresh: ${predictors.court.threshold}
    pose_vis_thresh: ${predictors.pose.pose_score_thresh}

  # ストリーミングオーバレイ設定（新規追加）
  streaming_overlayer:
    _target_: src.multi.streaming_overlayer.video_predictor.VideoPredictor
    # ball_predictor, court_predictor, pose_predictor は main.py で渡される
    intervals: {"ball": 1, "court": 30, "pose": 5}
    batch_sizes: {"ball": 16, "court": 16, "pose": 16}
    debug: false

  # マルチイベントオーバレイ設定（新規追加）
  multi_event:
    _target_: src.multi.streaming_overlayer.multi_event_predictor.MultiEventPredictor
    # 各単体predictorは main.py で渡される
    intervals: {"ball": 1, "court": 30, "pose": 5}
    batch_sizes: {"ball": 16, "court": 16, "pose": 16}
    event_sequence_length: 16
    debug: false