"""
æ‹¡å¼µå¯èƒ½ãªã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®é«˜åº¦ãªä½¿ç”¨ä¾‹ãƒ‡ãƒ¢

ã“ã®ãƒ‡ãƒ¢ã¯ä»¥ä¸‹ã®æ‹¡å¼µæ€§ã‚’å®Ÿè¨¼ã—ã¾ã™ï¼š
1. ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¥ãƒ¼è¨­å®š
2. å‹•çš„ãƒ¯ãƒ¼ã‚«ãƒ¼è¿½åŠ 
3. ç‰¹æ®Šç”¨é€”ã®ã‚­ãƒ¥ãƒ¼æ§‹æˆ
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–æ©Ÿèƒ½
"""
import queue
import threading
import time
from typing import Dict, Any, Optional

from src.multi.streaming_overlayer.queue_manager import (
    QueueManager, 
    QueueConfig, 
    create_queue_manager_for_video_predictor
)


def demo_basic_queue_configuration():
    """åŸºæœ¬çš„ãªã‚­ãƒ¥ãƒ¼è¨­å®šã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("1. åŸºæœ¬çš„ãªã‚­ãƒ¥ãƒ¼è¨­å®šãƒ‡ãƒ¢")
    print("=" * 60)
    
    # æ¨™æº–æ§‹æˆã§ã®QueueManagerä½œæˆ
    worker_names = ["ball", "court", "pose"]
    queue_manager = create_queue_manager_for_video_predictor(worker_names)
    
    print(f"âœ… åŸºæœ¬ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {len(queue_manager.worker_queue_sets)}")
    
    # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚­ãƒ¥ãƒ¼æ§‹æˆã‚’è¡¨ç¤º
    for worker_name in worker_names:
        queue_set = queue_manager.get_worker_queue_set(worker_name)
        base_queues = len(queue_set.base_queues)
        extended_queues = len(queue_set.extended_queues)
        print(f"  {worker_name}: åŸºæœ¬ã‚­ãƒ¥ãƒ¼ {base_queues}å€‹, æ‹¡å¼µã‚­ãƒ¥ãƒ¼ {extended_queues}å€‹")
    
    print()


def demo_custom_queue_configuration():
    """ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¥ãƒ¼è¨­å®šã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("2. ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¥ãƒ¼è¨­å®šãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã®å®šç¾©
    custom_configs = {
        "high_priority_inference": {
            "maxsize": 128,
            "queue_type": "PriorityQueue",
            "description": "é«˜å„ªå…ˆåº¦æ¨è«–å°‚ç”¨ã‚­ãƒ¥ãƒ¼"
        },
        "batch_processing": {
            "maxsize": 64,
            "queue_type": "Queue",
            "description": "ãƒãƒƒãƒå‡¦ç†ç”¨å¤§å®¹é‡ã‚­ãƒ¥ãƒ¼"
        },
        "emergency_queue": {
            "maxsize": 8,
            "queue_type": "LifoQueue",
            "description": "ç·Šæ€¥å‡¦ç†ç”¨LIFO ã‚­ãƒ¥ãƒ¼"
        }
    }
    
    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§QueueManagerä½œæˆ
    worker_names = ["ball"]
    queue_manager = create_queue_manager_for_video_predictor(worker_names, custom_configs)
    
    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã®ç¢ºèª
    for config_name, config_data in custom_configs.items():
        if config_name in queue_manager.queue_configs:
            config = queue_manager.queue_configs[config_name]
            print(f"âœ… {config_name}: maxsize={config.maxsize}, type={config.queue_type}")
            print(f"   èª¬æ˜: {config.description}")
        else:
            print(f"âŒ {config_name}: è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    print()


def demo_dynamic_worker_addition():
    """å‹•çš„ãƒ¯ãƒ¼ã‚«ãƒ¼è¿½åŠ ã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("3. å‹•çš„ãƒ¯ãƒ¼ã‚«ãƒ¼è¿½åŠ ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # åˆæœŸæ§‹æˆ
    queue_manager = QueueManager()
    queue_manager.initialize_results_queue()
    
    # æ®µéšçš„ã«ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’è¿½åŠ 
    worker_configs = [
        ("basic_worker", None),
        ("detection_worker", ["detection_inference", "detection_postprocess"]),
        ("pose_worker", ["detection_inference", "detection_postprocess", "pose_inference", "pose_postprocess"]),
        ("multi_stage_worker", ["detection_inference", "pose_inference", "ball_inference", "court_inference"])
    ]
    
    for worker_name, extended_queues in worker_configs:
        try:
            queue_manager.initialize_worker_queues(worker_name, extended_queues)
            queue_set = queue_manager.get_worker_queue_set(worker_name)
            base_count = len(queue_set.base_queues)
            extended_count = len(queue_set.extended_queues)
            print(f"âœ… {worker_name}: åŸºæœ¬ {base_count}å€‹, æ‹¡å¼µ {extended_count}å€‹")
        except Exception as e:
            print(f"âŒ {worker_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
    
    print()


def demo_performance_monitoring():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # QueueManagerã®ä½œæˆ
    worker_names = ["ball", "pose"]
    queue_manager = create_queue_manager_for_video_predictor(worker_names)
    
    # ã‚­ãƒ¥ãƒ¼ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    def populate_queues():
        """ã‚­ãƒ¥ãƒ¼ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´"""
        for i in range(10):
            # Ball worker ã‚­ãƒ¥ãƒ¼
            ball_preprocess_q = queue_manager.get_queue("ball", "preprocess")
            ball_preprocess_q.put(f"ball_task_{i}")
            
            # Pose worker æ‹¡å¼µã‚­ãƒ¥ãƒ¼
            pose_detection_q = queue_manager.get_queue("pose", "detection_inference")
            pose_pose_q = queue_manager.get_queue("pose", "pose_inference")
            pose_detection_q.put(f"detection_task_{i}")
            pose_pose_q.put(f"pose_task_{i}")
            
            # Results queue
            results_q = queue_manager.get_results_queue()
            results_q.put((i, "test", f"result_{i}"))
    
    # ã‚­ãƒ¥ãƒ¼ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
    populate_queues()
    
    # çŠ¶æ…‹ç›£è¦–
    status = queue_manager.get_queue_status()
    print(f"çµæœã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {status['results_queue_size']}")
    print()
    
    for worker_name, worker_status in status['workers'].items():
        print(f"[{worker_name.upper()}]")
        print("  åŸºæœ¬ã‚­ãƒ¥ãƒ¼:")
        for queue_name, size in worker_status['base_queues'].items():
            print(f"    {queue_name}: {size} items")
        
        if worker_status['extended_queues']:
            print("  æ‹¡å¼µã‚­ãƒ¥ãƒ¼:")
            for queue_name, size in worker_status['extended_queues'].items():
                print(f"    {queue_name}: {size} items")
        print()


def demo_queue_type_variations():
    """ç•°ãªã‚‹ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("5. ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¢")
    print("=" * 60)
    
    queue_manager = QueueManager()
    
    # ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®ã‚­ãƒ¥ãƒ¼ã‚’ä½œæˆ
    queue_types = [
        ("standard_queue", "Queue"),
        ("priority_queue", "results"),  # PriorityQueue
        ("lifo_queue", "emergency_queue")  # LifoQueue (custom config needed)
    ]
    
    # LIFOç”¨ã®ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’è¿½åŠ 
    lifo_config = QueueConfig("emergency_queue", 16, "LifoQueue", "ç·Šæ€¥ç”¨LIFOã‚­ãƒ¥ãƒ¼")
    queue_manager.add_queue_config(lifo_config)
    
    for queue_name, config_name in queue_types:
        try:
            q = queue_manager.create_queue_from_config(config_name)
            queue_type = type(q).__name__
            print(f"âœ… {queue_name}: {queue_type}")
            
            # å„ã‚­ãƒ¥ãƒ¼ã®å‹•ä½œãƒ†ã‚¹ãƒˆ
            if queue_type == "PriorityQueue":
                # å„ªå…ˆåº¦ä»˜ãã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ  (priority, item)
                q.put((1, "high_priority"))
                q.put((3, "low_priority"))
                q.put((2, "medium_priority"))
                
                print("   å„ªå…ˆåº¦é †å–å¾—ãƒ†ã‚¹ãƒˆ:")
                while not q.empty():
                    priority, item = q.get()
                    print(f"     Priority {priority}: {item}")
            
            elif queue_type == "LifoQueue":
                # LIFOé †ã§ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ 
                q.put("first")
                q.put("second")
                q.put("third")
                
                print("   LIFOé †å–å¾—ãƒ†ã‚¹ãƒˆ:")
                while not q.empty():
                    item = q.get()
                    print(f"     {item}")
            
            else:  # Standard Queue
                # FIFOé †ã§ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ 
                q.put("first")
                q.put("second")
                q.put("third")
                
                print("   FIFOé †å–å¾—ãƒ†ã‚¹ãƒˆ:")
                while not q.empty():
                    item = q.get()
                    print(f"     {item}")
            
        except Exception as e:
            print(f"âŒ {queue_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
        
        print()


def demo_scalability_test():
    """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("6. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    # å¤§é‡ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’æŒã¤æ§‹æˆã‚’ãƒ†ã‚¹ãƒˆ
    worker_names = [f"worker_{i}" for i in range(10)]
    
    start_time = time.time()
    queue_manager = create_queue_manager_for_video_predictor(worker_names)
    init_time = time.time() - start_time
    
    print(f"âœ… {len(worker_names)}å€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼åˆæœŸåŒ–æ™‚é–“: {init_time:.4f}ç§’")
    
    # çŠ¶æ…‹ç›£è¦–ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    start_time = time.time()
    status = queue_manager.get_queue_status()
    status_time = time.time() - start_time
    
    print(f"âœ… çŠ¶æ…‹ç›£è¦–å®Ÿè¡Œæ™‚é–“: {status_time:.4f}ç§’")
    print(f"âœ… ç®¡ç†ä¸­ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {len(status['workers'])}")
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¦‚ç®—
    total_queues = 0
    for worker_status in status['workers'].values():
        total_queues += len(worker_status['base_queues'])
        total_queues += len(worker_status['extended_queues'])
    
    print(f"âœ… ç·ã‚­ãƒ¥ãƒ¼æ•°: {total_queues}")
    print()


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ æ‹¡å¼µå¯èƒ½ã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ  - é«˜åº¦ãªä½¿ç”¨ä¾‹ãƒ‡ãƒ¢")
    print("ã“ã®ãƒ‡ãƒ¢ã¯video_predictorå´ã§ã®ã‚­ãƒ¥ãƒ¼åˆæœŸåŒ–ã¨å°†æ¥ã®æ‹¡å¼µæ€§ã‚’å®Ÿè¨¼ã—ã¾ã™")
    print()
    
    # å„ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
    demo_basic_queue_configuration()
    demo_custom_queue_configuration()
    demo_dynamic_worker_addition()
    demo_performance_monitoring()
    demo_queue_type_variations()
    demo_scalability_test()
    
    print("=" * 60)
    print("ğŸ‰ ãƒ‡ãƒ¢å®Œäº† - æ‹¡å¼µå¯èƒ½ãªã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®æŸ”è»Ÿæ€§ã‚’ç¢ºèªï¼")
    print("=" * 60)
    
    print("\nğŸ“ ä¸»ãªæ‹¡å¼µæ€§ãƒã‚¤ãƒ³ãƒˆ:")
    print("  âœ… video_predictorå´ã§ã®ã‚­ãƒ¥ãƒ¼ç®¡ç†")
    print("  âœ… predictoræ•°ã«åˆ¶é™ã•ã‚Œãªã„æŸ”è»Ÿãªã‚­ãƒ¥ãƒ¼æ§‹æˆ")
    print("  âœ… ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¥ãƒ¼è¨­å®šã«ã‚ˆã‚‹ç‰¹æ®Šç”¨é€”å¯¾å¿œ")
    print("  âœ… å‹•çš„ãƒ¯ãƒ¼ã‚«ãƒ¼è¿½åŠ æ©Ÿèƒ½")
    print("  âœ… è¤‡æ•°ã®ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã‚µãƒãƒ¼ãƒˆ")
    print("  âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŠ¶æ…‹ç›£è¦–")
    print("  âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªè¨­è¨ˆ")


if __name__ == "__main__":
    main() 