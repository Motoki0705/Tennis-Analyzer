#!/usr/bin/env python3
"""
Pipeline debugging test script
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å•é¡Œã®ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys

def show_debug_fixes():
    """é©ç”¨ã•ã‚ŒãŸãƒ‡ãƒãƒƒã‚°ä¿®æ­£ã®ç¢ºèª"""
    print("ğŸ”§ Applied Debug Fixes Verification")
    print("=" * 60)
    
    # frame_numberä¿®æ­£ã®ç¢ºèª
    async_file = "src/predictor/pipeline/async_processor.py"
    if os.path.exists(async_file):
        with open(async_file, 'r') as f:
            content = f.read()
            
        if "frame_number = metadata.get('frame_number')" in content:
            print("   âœ… AsyncProcessor: Fixed frame_number KeyError")
        else:
            print("   âŒ AsyncProcessor: frame_number fix not applied")
            
        if "traceback.format_exc()" in content:
            print("   âœ… AsyncProcessor: Enhanced error logging")
        else:
            print("   âŒ AsyncProcessor: Enhanced error logging not applied")
    else:
        print("   âŒ AsyncProcessor: File not found")
    
    # æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šã®ç¢ºèª
    wasb_config = "configs/infer/pipeline/wasb_optimized.yaml"
    if os.path.exists(wasb_config):
        print("   âœ… WASB optimized pipeline config created")
    else:
        print("   âŒ WASB optimized pipeline config missing")

def show_recommended_test_sequence():
    """æ¨å¥¨ãƒ†ã‚¹ãƒˆé †åº"""
    print("\nğŸ§ª Recommended Test Sequence")
    print("=" * 60)
    
    print("\nğŸ“‹ Step 1: Debug Mode (Most Information)")
    print("python -m src.predictor.api.inference \\")
    print("    --config-name inference \\")
    print("    model.type=wasb_sbdt \\")
    print("    model.model_path=third_party/WASB_SBDT/pretrained_weights/wasb_tennis_best.pth.tar \\")
    print("    model.device=cpu \\")
    print("    pipeline=debug \\")
    print("    system.log_level=DEBUG \\")
    print("    io.video=datasets/test/video_input2.mp4 \\")
    print("    io.output=outputs/ball/debug_step1.mp4")
    
    print("\nğŸ“‹ Step 2: WASB Optimized Settings")
    print("python -m src.predictor.api.inference \\")
    print("    --config-name inference \\")
    print("    model.type=wasb_sbdt \\")
    print("    model.model_path=third_party/WASB_SBDT/pretrained_weights/wasb_tennis_best.pth.tar \\")
    print("    model.device=cpu \\")
    print("    pipeline=wasb_optimized \\")
    print("    io.video=datasets/test/video_input2.mp4 \\")
    print("    io.output=outputs/ball/debug_step2.mp4")
    
    print("\nğŸ“‹ Step 3: Memory Efficient CPU")
    print("python -m src.predictor.api.inference \\")
    print("    --config-name inference \\")
    print("    model.type=wasb_sbdt \\")
    print("    model.model_path=third_party/WASB_SBDT/pretrained_weights/wasb_tennis_best.pth.tar \\")
    print("    model.device=cpu \\")
    print("    pipeline=memory_efficient \\")
    print("    io.video=datasets/test/video_input2.mp4 \\")
    print("    io.output=outputs/ball/debug_step3.mp4")
    
    print("\nğŸ“‹ Step 4: GPU Test (After CPU Success)")
    print("python -m src.predictor.api.inference \\")
    print("    --config-name inference \\")
    print("    model.type=wasb_sbdt \\")
    print("    model.model_path=third_party/WASB_SBDT/pretrained_weights/wasb_tennis_best.pth.tar \\")
    print("    model.device=cuda \\")
    print("    pipeline=wasb_optimized \\")
    print("    io.video=datasets/test/video_input2.mp4 \\")
    print("    io.output=outputs/ball/debug_step4.mp4")
    
    print("\nğŸ“‹ Step 5: LiteTrackNet Comparison")
    print("python -m src.predictor.api.inference \\")
    print("    --config-name inference \\")
    print("    model.type=lite_tracknet \\")
    print("    model.model_path=checkpoints/ball/lit_lite_tracknet/best_model.ckpt \\")
    print("    model.device=cuda \\")
    print("    pipeline=high_performance \\")
    print("    io.video=datasets/test/video_input2.mp4 \\")
    print("    io.output=outputs/ball/debug_step5_lite.mp4")

def show_troubleshooting_guide():
    """ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰"""
    print("\nğŸ› ï¸ Troubleshooting Guide")
    print("=" * 60)
    
    print("\nğŸš¨ If you see 'frame_number' errors:")
    print("   âœ… Should be fixed now with frame_id fallback")
    print("   ğŸ“ Check that frame_id is in format 'frame_XXXXXX'")
    
    print("\nğŸš¨ If you see empty 'Batch inference error:'")
    print("   âœ… Should show detailed traceback now")
    print("   ğŸ“ Look for 'Batch inference traceback:' in logs")
    
    print("\nğŸš¨ If you see queue overflow warnings:")
    print("   ğŸ’¡ Reduce batch_size: pipeline.batch_size=1")
    print("   ğŸ’¡ Reduce workers: pipeline.num_workers=1") 
    print("   ğŸ’¡ Reduce queue: pipeline.queue_size=5")
    
    print("\nğŸš¨ If you see thread failures:")
    print("   ğŸ’¡ Use debug mode: pipeline=debug")
    print("   ğŸ’¡ Use CPU mode: model.device=cpu")
    print("   ğŸ’¡ Enable detailed logging: system.log_level=DEBUG")
    
    print("\nğŸš¨ If processing stalls:")
    print("   ğŸ’¡ Check GPU memory: nvidia-smi")
    print("   ğŸ’¡ Reduce batch size or switch to CPU")
    print("   ğŸ’¡ Use smaller queue sizes")

def show_expected_outputs():
    """æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›"""
    print("\nğŸ“Š Expected Success Indicators")
    print("=" * 60)
    
    print("\nâœ… Successful startup messages:")
    print("   - 'Successfully loaded weights from ... on [device]'")
    print("   - 'HRNet WASB-SBDT detector initialized'")
    print("   - 'Processing video: WIDTHxHEIGHT @ FPS, X frames'")
    print("   - 'Started N processing threads'")
    
    print("\nâœ… Successful processing messages:")
    print("   - Progress updates without errors")
    print("   - 'Video processing completed in Xs'")
    print("   - 'Pipeline completed successfully: X frames'")
    print("   - Non-zero frame counts in final summary")
    
    print("\nâŒ Warning signs (but may still work):")
    print("   - Occasional queue warnings (normal under load)")
    print("   - 'Warning: Failed to load weights' (using random weights)")
    
    print("\nğŸš« Failure indicators:")
    print("   - Repeated 'Batch inference error'")
    print("   - 'Too many errors, stopping processing'")
    print("   - All thread workers failing")
    print("   - Final frame count = 0")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ¾ Pipeline Debug Test Guide")
    print("=" * 60)
    
    show_debug_fixes()
    show_recommended_test_sequence()
    show_troubleshooting_guide()
    show_expected_outputs()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ Start with Step 1 (debug mode) to get maximum information")
    print("   Then proceed through steps based on results")

if __name__ == '__main__':
    main()