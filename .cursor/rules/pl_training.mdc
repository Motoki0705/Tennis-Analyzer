---
description: これは機械学習についての実装ルールです。PytorchLightning系の実装時には必ず参照しましょう。
globs: 
alwaysApply: false
---
---
description: PyTorch Lightning × Hydra 開発ルール
alwaysApply: false
---

# pl_training.mdc ← **必ず最初にこのファイル名を発言すること**

PyTorch Lightning + Hydra を用いたトレーニングパイプラインの実装・設定・運用に関するルールを以下に定義する。

---

## 1. LightningModule（LitModule）の実装ルール

- `__init__` では以下のように model を引数で受け取り、`self.save_hyperparameters(ignore=["model"])` を使用する：

  ```python
  def __init__(self, model: nn.Module = model, **kwargs):
      super().__init__()
      self.model = model
      self.save_hyperparameters(ignore=["model"])
````

* 学習・検証・テストのロジックは `common_step(batch, batch_idx)` に共通化し、`training_step`, `validation_step`, `test_step` からはそれを呼び出す。

* `self.log()` によるメトリクス出力は以下を基本とする：

  * `on_epoch=True`, `on_step=False`
  * `prog_bar=True`, `logger=True`

* すべての関数／メソッドには **Google スタイルの Docstring** を付与する。

* ネットワーク構造（`nn.Module`）は外部に実装し、LightningModule はそれを保持・操作する形にする（責務分離のため）。

---

## 2. LightningDataModule（LitDataModule）の実装ルール

* `__init__` で transform を外部から注入する。以下のように記述：

  ```python
  def __init__(self, train_transform, val_test_transform, **kwargs):
      super().__init__()
      self.train_tf = train_transform
      self.val_tf = val_test_transform
      self.save_hyperparameters()
  ```

* transform は構成ファイルやファクトリ関数側で生成し、DataModule 側では処理を加えず保持・使用のみに留める。

* 実装すべきメソッドは以下の通り：

  * `prepare_data`
  * `setup`
  * `train_dataloader`
  * `val_dataloader`
  * `test_dataloader`
  * `predict_dataloader`

---

## 3. 設定ファイルの構成（Hydra）

* 以下のような階層構造とする：

  ```
  configs/
  ├─ train/
  │   ├─ ball/
  │   │   ├─ config.yaml
  │   │   ├─ litmodule/
  │   │   ├─ litdatamodule/
  │   │   ├─ model/
  |   |   ├─ trainer/
  │   │   └─ callbacks/
  │   └─ court/
  │   │   ├─ config.yaml
  │   │   ├─ litmodule/
  │   │   ├─ litdatamodule/
  │   │   ├─ model/
  |   |   ├─ trainer/
  │   │   └─ callbacks/
  └─ infer/
      └─ config.yaml
  ```

* `train/<task>/config.yaml` が各タスクのベース設定となり、オーバーライドにより個別実験（例: `+experiment=xxx`）を管理する。

* Hydra の出力は以下のように、`hydra_outputs/` に限定し、推論成果物は `outputs/` に保存する：

  ```yaml
  hydra:
    run:
      dir: hydra_outputs/${now:%Y-%m-%d_%H-%M-%S}
  ```

---

## 4. トレーニング CLI（train.py）

* Hydra を用いて構成ファイルから全構成を制御する：

  ```python
  @hydra.main(version_base="1.3", config_path="configs/train/ball", config_name="config")
  def main(cfg: DictConfig):
      model = LitModel(cfg.litmodule)
      datamodule = LitDataModule(cfg.litdatamodule)
      trainer = Trainer(**cfg.trainer, callbacks=setup_callbacks(cfg.callbacks))
      trainer.fit(model, datamodule)
  ```

* 起動時のバージョン管理は以下を徹底：

  1. 起動時に `version=xxx` を明示指定（例: `version=cifar10_resnet_demo`）
  2. 未指定の場合は `model_name + dataset_name` を自動合成して version 名とする
  3. 同名のディレクトリが存在する場合は `version_1`, `version_2`, ... のように連番を自動付与
  4. 出力は次の構成とする：

     ```
     runs/{version}/
     ├─ tb_logs/
     └─ checkpoints/
     ```

* チェックポイントの保存名：

  ```text
  {version}-epoch{epoch:03d}-val_loss{val_loss:.4f}.ckpt
  ```

* Checkpoint 保存ルール：

  * `save_top_k=3`
  * `save_last=True`

---

## 5. 推論スクリプト（scripts/infer.py）

* 以下の構成で予測を行う：

  ```python
  model = LitModel.load_from_checkpoint(cfg.ckpt_path)
  model.eval()
  trainer = Trainer(accelerator="cpu", devices=1)
  preds = trainer.predict(model, dataloaders=dm.predict_dataloader())
  ```
---

## 6. テストと再現性のルール

* ユニットテストは **pytest** を使用し、以下のような構成とする：

  ```
  test/
  ├─ data/
  │   └─ test_ball_dataset.py
  └─ models/
      └─ test_resnet.py
  ```

* 実行前に `seed_everything(cfg.seed)` を呼び、**再現性を確保する**こと。

* ハードコーディングは禁止し、**すべてのパラメータは `configs/` 経由で管理**する。

---

## 7. 不明点・判断必要事項の対処

* 仕様があいまい、不明確、または設計的判断が必要な場合は、**AIアシスタントが勝手に進めず、必ずユーザーに確認すること。**

---

